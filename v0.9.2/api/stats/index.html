<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Stats · ArviZ.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="stable/api/stats/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="ArviZ.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="ArviZ.jl logo"/></a><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../../working_with_inference_data/">Working with <code>InferenceData</code></a></li><li><a class="tocitem" href="../../creating_custom_plots/">Creating custom plots</a></li></ul></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Stats</a><ul class="internal"><li><a class="tocitem" href="#Summary-statistics"><span>Summary statistics</span></a></li><li><a class="tocitem" href="#General-statistics"><span>General statistics</span></a></li><li><a class="tocitem" href="#Pareto-smoothed-importance-sampling"><span>Pareto-smoothed importance sampling</span></a></li><li><a class="tocitem" href="#LOO-and-WAIC"><span>LOO and WAIC</span></a></li><li><a class="tocitem" href="#Model-comparison"><span>Model comparison</span></a></li><li><a class="tocitem" href="#Predictive-checks"><span>Predictive checks</span></a></li></ul></li><li><a class="tocitem" href="../diagnostics/">Diagnostics</a></li><li><a class="tocitem" href="../data/">Data</a></li><li><input class="collapse-toggle" id="menuitem-3-5" type="checkbox"/><label class="tocitem" for="menuitem-3-5"><span class="docs-label">InferenceObjects</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../inference_data/">InferenceData</a></li><li><a class="tocitem" href="../dataset/">Dataset</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Stats</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Stats</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/arviz-devs/ArviZ.jl/blob/main/docs/src/api/stats.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="stats-api"><a class="docs-heading-anchor" href="#stats-api">Stats</a><a id="stats-api-1"></a><a class="docs-heading-anchor-permalink" href="#stats-api" title="Permalink"></a></h1><ul><li><a href="#ArviZ.ArviZStats.AbstractELPDResult"><code>ArviZ.ArviZStats.AbstractELPDResult</code></a></li><li><a href="#ArviZ.ArviZStats.AbstractModelWeightsMethod"><code>ArviZ.ArviZStats.AbstractModelWeightsMethod</code></a></li><li><a href="#ArviZ.ArviZStats.BootstrappedPseudoBMA"><code>ArviZ.ArviZStats.BootstrappedPseudoBMA</code></a></li><li><a href="#ArviZ.ArviZStats.ModelComparisonResult"><code>ArviZ.ArviZStats.ModelComparisonResult</code></a></li><li><a href="#ArviZ.ArviZStats.PSISLOOResult"><code>ArviZ.ArviZStats.PSISLOOResult</code></a></li><li><a href="#ArviZ.ArviZStats.PseudoBMA"><code>ArviZ.ArviZStats.PseudoBMA</code></a></li><li><a href="#ArviZ.ArviZStats.Stacking"><code>ArviZ.ArviZStats.Stacking</code></a></li><li><a href="#ArviZ.ArviZStats.SummaryStats"><code>ArviZ.ArviZStats.SummaryStats</code></a></li><li><a href="#ArviZ.ArviZStats.WAICResult"><code>ArviZ.ArviZStats.WAICResult</code></a></li><li><a href="#PSIS.PSISResult"><code>PSIS.PSISResult</code></a></li><li><a href="#ArviZ.ArviZStats.compare"><code>ArviZ.ArviZStats.compare</code></a></li><li><a href="#ArviZ.ArviZStats.elpd_estimates"><code>ArviZ.ArviZStats.elpd_estimates</code></a></li><li><a href="#ArviZ.ArviZStats.hdi"><code>ArviZ.ArviZStats.hdi</code></a></li><li><a href="#ArviZ.ArviZStats.hdi!"><code>ArviZ.ArviZStats.hdi!</code></a></li><li><a href="#ArviZ.ArviZStats.information_criterion"><code>ArviZ.ArviZStats.information_criterion</code></a></li><li><a href="#ArviZ.ArviZStats.loo"><code>ArviZ.ArviZStats.loo</code></a></li><li><a href="#ArviZ.ArviZStats.loo_pit"><code>ArviZ.ArviZStats.loo_pit</code></a></li><li><a href="#ArviZ.ArviZStats.model_weights"><code>ArviZ.ArviZStats.model_weights</code></a></li><li><a href="#ArviZ.ArviZStats.r2_score"><code>ArviZ.ArviZStats.r2_score</code></a></li><li><a href="#ArviZ.ArviZStats.smooth_data"><code>ArviZ.ArviZStats.smooth_data</code></a></li><li><a href="#ArviZ.ArviZStats.waic"><code>ArviZ.ArviZStats.waic</code></a></li><li><a href="#PSIS.psis"><code>PSIS.psis</code></a></li><li><a href="#PSIS.psis!"><code>PSIS.psis!</code></a></li><li><a href="#StatsBase.summarystats"><code>StatsBase.summarystats</code></a></li></ul><h2 id="Summary-statistics"><a class="docs-heading-anchor" href="#Summary-statistics">Summary statistics</a><a id="Summary-statistics-1"></a><a class="docs-heading-anchor-permalink" href="#Summary-statistics" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.SummaryStats" href="#ArviZ.ArviZStats.SummaryStats"><code>ArviZ.ArviZStats.SummaryStats</code></a> — <span class="docstring-category">Type</span></header><section><div><p>A container for a column table of values computed by <a href="#StatsBase.summarystats"><code>summarystats</code></a>.</p><p>This object implements the Tables and TableTraits interfaces and has a custom <code>show</code> method.</p><ul><li><code>data</code>: The summary statistics for each variable, with the first entry containing the variable names</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/summarystats.jl#L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsBase.summarystats" href="#StatsBase.summarystats"><code>StatsBase.summarystats</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">summarystats(data::InferenceData; group=:posterior, kwargs...)
summarystats(data::Dataset; kwargs...)</code></pre><p>Compute summary statistics and diagnostics on the <code>data</code>.</p><p><strong>Keywords</strong></p><ul><li><code>prob_interval::Real</code>: The value of the <code>prob</code> argument to <a href="#ArviZ.ArviZStats.hdi"><code>hdi</code></a> used to compute the highest density interval. Defaults to 0.94.</li><li><code>return_type::Type</code>: The type of object to return. Valid options are <a href="api/@ref"><code>Dataset</code></a> and <a href="#ArviZ.ArviZStats.SummaryStats"><code>SummaryStats</code></a>. Defaults to <code>SummaryStats</code>.</li><li><code>metric_dim</code>: The dimension name or type to use for the computed metrics. Only used if <code>return_type</code> is <code>Dataset</code>. Defaults to <code>Dim{:_metric}</code>.</li><li><code>compact_labels::Bool</code>: Whether to use compact names for the variables. Only used if <code>return_type</code> is <code>SummaryStats</code>. Defaults to <code>true</code>.</li><li><code>kind::Symbol</code>: Whether to compute just statistics (<code>:stats</code>), just diagnostics (<code>:diagnostics</code>), or both (<code>:both</code>). Defaults to <code>:both</code>.</li></ul><p><strong>Examples</strong></p><p>Compute the summary statistics and diagnostics on posterior draws of the centered eight model:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; summarystats(idata.posterior[(:mu, :tau)])
SummaryStats
      mean  std  hdi_3%  hdi_97%  mcse_mean  mcse_std  ess_tail  ess_bulk  rha ⋯
 mu    4.5  3.5  -1.62     10.7        0.23      0.11       659       241  1.0 ⋯
 tau   4.1  3.1   0.896     9.67       0.26      0.17        38        67  1.0 ⋯
                                                                1 column omitted</code></pre><p>Compute just the statistics on all variables:</p><pre><code class="language-julia-repl hljs">julia&gt; summarystats(idata.posterior; kind=:stats)
SummaryStats
                          mean   std  hdi_3%  hdi_97%
 mu                       4.49  3.49  -1.62     10.7
 theta[Choate]            6.46  5.87  -4.56     17.1
 theta[Deerfield]         5.03  4.88  -4.31     14.3
 theta[Phillips Andover]  3.94  5.69  -7.77     13.7
 theta[Phillips Exeter]   4.87  5.01  -4.49     14.7
 theta[Hotchkiss]         3.67  4.96  -6.47     11.7
 theta[Lawrenceville]     3.97  5.19  -7.04     12.2
 theta[St. Paul&#39;s]        6.58  5.11  -3.09     16.3
 theta[Mt. Hermon]        4.77  5.74  -5.86     16.0
 tau                      4.12  3.10   0.896     9.67</code></pre><p>Compute the statistics and diagnostics from the posterior group of an <code>InferenceData</code> and store in a <code>Dataset</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; summarystats(idata; return_type=Dataset)
Dataset with dimensions:
  Dim{:_metric} Categorical{String} String[mean, std, …, ess_bulk, rhat] Unordered,
  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul&#39;s, Mt. Hermon] Unordered
and 3 layers:
  :mu    Float64 dims: Dim{:_metric} (9)
  :theta Float64 dims: Dim{:school}, Dim{:_metric} (8×9)
  :tau   Float64 dims: Dim{:_metric} (9)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/summarystats.jl#L74-L142">source</a></section></article><h2 id="General-statistics"><a class="docs-heading-anchor" href="#General-statistics">General statistics</a><a id="General-statistics-1"></a><a class="docs-heading-anchor-permalink" href="#General-statistics" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.hdi" href="#ArviZ.ArviZStats.hdi"><code>ArviZ.ArviZStats.hdi</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">hdi(samples::AbstractArray{&lt;:Real}; prob=0.94) -&gt; (; lower, upper)</code></pre><p>Estimate the unimodal highest density interval (HDI) of <code>samples</code> for the probability <code>prob</code>.</p><p>The HDI is the minimum width Bayesian credible interval (BCI). That is, it is the smallest possible interval containing at least <code>(100*prob)</code>% of the draws.<sup class="footnote-reference"><a id="citeref-Hyndman1996" href="#footnote-Hyndman1996">[Hyndman1996]</a></sup></p><p><code>samples</code> is an array of shape <code>(draws[, chains[, params...]])</code>. If multiple parameters are present, then <code>lower</code> and <code>upper</code> are arrays with the shape <code>(params...,)</code>, computed separately for each marginal.</p><p>This implementation uses the algorithm of <sup class="footnote-reference"><a id="citeref-ChenShao1999" href="#footnote-ChenShao1999">[ChenShao1999]</a></sup>.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Any default value of <code>prob</code> is arbitrary. The default value of <code>prob=0.94</code> instead of a more common default like <code>prob=0.95</code> is chosen to reminder the user of this arbitrariness.</p></div></div><p><strong>Examples</strong></p><p>Here we calculate the 83% HDI for a normal random variable:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ

julia&gt; x = randn(2_000);

julia&gt; hdi(x; prob=0.83) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :lower =&gt; -1.38266
  :upper =&gt; 1.25982</code></pre><p>We can also calculate the HDI for a 3-dimensional array of samples:</p><pre><code class="language-julia-repl hljs">julia&gt; x = randn(1_000, 1, 1) .+ reshape(0:5:10, 1, 1, :);

julia&gt; hdi(x) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :lower =&gt; [-1.9674, 3.0326, 8.0326]
  :upper =&gt; [1.90028, 6.90028, 11.9003]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/hdi.jl#L6-L60">source</a></section><section><div><pre><code class="nohighlight hljs">hdi(data::InferenceData; prob=0.94) -&gt; Dataset
hdi(data::Dataset; prob=0.94) -&gt; Dataset</code></pre><p>Calculate the highest density interval (HDI) for each parameter in the data.</p><p><strong>Examples</strong></p><p>Calculate HDI for all parameters in the <code>posterior</code> group of an <code>InferenceData</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; hdi(idata)
Dataset with dimensions:
  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul&#39;s, Mt. Hermon] Unordered,
  Dim{:hdi_bound} Categorical{Symbol} Symbol[:lower, :upper] ForwardOrdered
and 3 layers:
  :mu    Float64 dims: Dim{:hdi_bound} (2)
  :theta Float64 dims: Dim{:school}, Dim{:hdi_bound} (8×2)
  :tau   Float64 dims: Dim{:hdi_bound} (2)</code></pre><p>We can also calculate the HDI for a subset of variables:</p><pre><code class="language-julia-repl hljs">julia&gt; hdi(idata.posterior[(:theta,)]).theta
8×2 DimArray{Float64,2} theta with dimensions:
  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul&#39;s, Mt. Hermon] Unordered,
  Dim{:hdi_bound} Categorical{Symbol} Symbol[:lower, :upper] ForwardOrdered
                        :lower    :upper
  &quot;Choate&quot;            -4.56375  17.1324
  &quot;Deerfield&quot;         -4.31055  14.2535
  &quot;Phillips Andover&quot;  -7.76922  13.6755
  &quot;Phillips Exeter&quot;   -4.48955  14.6635
  &quot;Hotchkiss&quot;         -6.46991  11.7191
  &quot;Lawrenceville&quot;     -7.04111  12.2087
  &quot;St. Paul&#39;s&quot;        -3.09262  16.2685
  &quot;Mt. Hermon&quot;        -5.85834  16.0143</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/hdi.jl#L105-L147">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.hdi!" href="#ArviZ.ArviZStats.hdi!"><code>ArviZ.ArviZStats.hdi!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">hdi!(samples::AbstractArray{&lt;:Real}; prob=0.94) -&gt; (; lower, upper)</code></pre><p>A version of <a href="api/@ref">hdi</a> that sorts <code>samples</code> in-place while computing the HDI.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/hdi.jl#L67-L71">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.r2_score" href="#ArviZ.ArviZStats.r2_score"><code>ArviZ.ArviZStats.r2_score</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">r2_score(y_true::AbstractVector, y_pred::AbstractVecOrMat) -&gt; (; r2, r2_std)</code></pre><p><span>$R²$</span> for linear Bayesian regression models.<sup class="footnote-reference"><a id="citeref-GelmanGoodrich2019" href="#footnote-GelmanGoodrich2019">[GelmanGoodrich2019]</a></sup></p><p><strong>Arguments</strong></p><ul><li><code>y_true</code>: Observed data of length <code>noutputs</code></li><li><code>y_pred</code>: Predicted data with size <code>(ndraws[, nchains], noutputs)</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;regression1d&quot;);

julia&gt; y_true = idata.observed_data.y;

julia&gt; y_pred = PermutedDimsArray(idata.posterior_predictive.y, (:draw, :chain, :y_dim_0));

julia&gt; r2_score(y_true, y_pred) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :r2     =&gt; 0.683197
  :r2_std =&gt; 0.0368838</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/r2_score.jl#L1-L32">source</a></section><section><div><pre><code class="nohighlight hljs">r2_score(idata::InferenceData; y_name, y_pred_name) -&gt; (; r2, r2_std)</code></pre><p>Compute <span>$R²$</span> from <code>idata</code>, automatically formatting the predictions to the correct shape.</p><p><strong>Keywords</strong></p><ul><li><code>y_name</code>: Name of observed data variable in <code>idata.observed_data</code>. If not provided, then the only observed data variable is used.</li><li><code>y_pred_name</code>: Name of posterior predictive variable in <code>idata.posterior_predictive</code>. If not provided, then <code>y_name</code> is used.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;regression10d&quot;);

julia&gt; r2_score(idata) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :r2     =&gt; 0.998385
  :r2_std =&gt; 0.000100621</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/r2_score.jl#L38-L62">source</a></section></article><h2 id="Pareto-smoothed-importance-sampling"><a class="docs-heading-anchor" href="#Pareto-smoothed-importance-sampling">Pareto-smoothed importance sampling</a><a id="Pareto-smoothed-importance-sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Pareto-smoothed-importance-sampling" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="PSIS.PSISResult" href="#PSIS.PSISResult"><code>PSIS.PSISResult</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PSISResult</code></pre><p>Result of Pareto-smoothed importance sampling (PSIS) using <a href="#PSIS.psis"><code>psis</code></a>.</p><p><strong>Properties</strong></p><ul><li><code>log_weights</code>: un-normalized Pareto-smoothed log weights</li><li><code>weights</code>: normalized Pareto-smoothed weights (allocates a copy)</li><li><code>pareto_shape</code>: Pareto <span>$k=ξ$</span> shape parameter</li><li><code>nparams</code>: number of parameters in <code>log_weights</code></li><li><code>ndraws</code>: number of draws in <code>log_weights</code></li><li><code>nchains</code>: number of chains in <code>log_weights</code></li><li><code>reff</code>: the ratio of the effective sample size of the unsmoothed importance ratios and the actual sample size.</li><li><code>ess</code>: estimated effective sample size of estimate of mean using smoothed importance samples (see <a href="api/@ref"><code>ess_is</code></a>)</li><li><code>tail_length</code>: length of the upper tail of <code>log_weights</code> that was smoothed</li><li><code>tail_dist</code>: the generalized Pareto distribution that was fit to the tail of <code>log_weights</code>. Note that the tail weights are scaled to have a maximum of 1, so <code>tail_dist * exp(maximum(log_ratios))</code> is the corresponding fit directly to the tail of <code>log_ratios</code>.</li><li><code>normalized::Bool</code>:indicates whether <code>log_weights</code> are log-normalized along the sample dimensions.</li></ul><p><strong>Diagnostic</strong></p><p>The <code>pareto_shape</code> parameter <span>$k=ξ$</span> of the generalized Pareto distribution <code>tail_dist</code> can be used to diagnose reliability and convergence of estimates using the importance weights <sup class="footnote-reference"><a id="citeref-VehtariSimpson2021" href="#footnote-VehtariSimpson2021">[VehtariSimpson2021]</a></sup>.</p><ul><li>if <span>$k &lt; \frac{1}{3}$</span>, importance sampling is stable, and importance sampling (IS) and PSIS both are reliable.</li><li>if <span>$k ≤ \frac{1}{2}$</span>, then the importance ratio distributon has finite variance, and the central limit theorem holds. As <span>$k$</span> approaches the upper bound, IS becomes less reliable, while PSIS still works well but with a higher RMSE.</li><li>if <span>$\frac{1}{2} &lt; k ≤ 0.7$</span>, then the variance is infinite, and IS can behave quite poorly. However, PSIS works well in this regime.</li><li>if <span>$0.7 &lt; k ≤ 1$</span>, then it quickly becomes impractical to collect enough importance weights to reliably compute estimates, and importance sampling is not recommended.</li><li>if <span>$k &gt; 1$</span>, then neither the variance nor the mean of the raw importance ratios exists. The convergence rate is close to zero, and bias can be large with practical sample sizes.</li></ul><p>See <a href="api/@ref"><code>PSISPlots.paretoshapeplot</code></a> for a diagnostic plot.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="PSIS.psis" href="#PSIS.psis"><code>PSIS.psis</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">psis(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult
psis!(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult</code></pre><p>Compute Pareto smoothed importance sampling (PSIS) log weights <sup class="footnote-reference"><a id="citeref-VehtariSimpson2021" href="#footnote-VehtariSimpson2021">[VehtariSimpson2021]</a></sup>.</p><p>While <code>psis</code> computes smoothed log weights out-of-place, <code>psis!</code> smooths them in-place.</p><p><strong>Arguments</strong></p><ul><li><code>log_ratios</code>: an array of logarithms of importance ratios, with size <code>(draws, [chains, [parameters...]])</code>, where <code>chains&gt;1</code> would be used when chains are generated using Markov chain Monte Carlo.</li><li><code>reff::Union{Real,AbstractArray}</code>: the ratio(s) of effective sample size of <code>log_ratios</code> and the actual sample size <code>reff = ess/(draws * chains)</code>, used to account for autocorrelation, e.g. due to Markov chain Monte Carlo. If an array, it must have the size <code>(parameters...,)</code> to match <code>log_ratios</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>warn=true</code>: If <code>true</code>, warning messages are delivered</li><li><code>normalize=true</code>: If <code>true</code>, the log-weights will be log-normalized so that <code>exp.(log_weights)</code> sums to 1 along the sample dimensions.</li></ul><p><strong>Returns</strong></p><ul><li><code>result</code>: a <a href="#PSIS.PSISResult"><code>PSISResult</code></a> object containing the results of the Pareto-smoothing.</li></ul><p>A warning is raised if the Pareto shape parameter <span>$k ≥ 0.7$</span>. See <a href="#PSIS.PSISResult"><code>PSISResult</code></a> for details and <a href="api/@ref"><code>PSISPlots.paretoshapeplot</code></a> for a diagnostic plot.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="PSIS.psis!" href="#PSIS.psis!"><code>PSIS.psis!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">psis(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult
psis!(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult</code></pre><p>Compute Pareto smoothed importance sampling (PSIS) log weights <sup class="footnote-reference"><a id="citeref-VehtariSimpson2021" href="#footnote-VehtariSimpson2021">[VehtariSimpson2021]</a></sup>.</p><p>While <code>psis</code> computes smoothed log weights out-of-place, <code>psis!</code> smooths them in-place.</p><p><strong>Arguments</strong></p><ul><li><code>log_ratios</code>: an array of logarithms of importance ratios, with size <code>(draws, [chains, [parameters...]])</code>, where <code>chains&gt;1</code> would be used when chains are generated using Markov chain Monte Carlo.</li><li><code>reff::Union{Real,AbstractArray}</code>: the ratio(s) of effective sample size of <code>log_ratios</code> and the actual sample size <code>reff = ess/(draws * chains)</code>, used to account for autocorrelation, e.g. due to Markov chain Monte Carlo. If an array, it must have the size <code>(parameters...,)</code> to match <code>log_ratios</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>warn=true</code>: If <code>true</code>, warning messages are delivered</li><li><code>normalize=true</code>: If <code>true</code>, the log-weights will be log-normalized so that <code>exp.(log_weights)</code> sums to 1 along the sample dimensions.</li></ul><p><strong>Returns</strong></p><ul><li><code>result</code>: a <a href="#PSIS.PSISResult"><code>PSISResult</code></a> object containing the results of the Pareto-smoothing.</li></ul><p>A warning is raised if the Pareto shape parameter <span>$k ≥ 0.7$</span>. See <a href="#PSIS.PSISResult"><code>PSISResult</code></a> for details and <a href="api/api/@ref"><code>PSISPlots.paretoshapeplot</code></a> for a diagnostic plot.</p></div></section></article><h2 id="LOO-and-WAIC"><a class="docs-heading-anchor" href="#LOO-and-WAIC">LOO and WAIC</a><a id="LOO-and-WAIC-1"></a><a class="docs-heading-anchor-permalink" href="#LOO-and-WAIC" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.AbstractELPDResult" href="#ArviZ.ArviZStats.AbstractELPDResult"><code>ArviZ.ArviZStats.AbstractELPDResult</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type AbstractELPDResult</code></pre><p>An abstract type representing the result of an ELPD computation.</p><p>Every subtype stores estimates of both the expected log predictive density (<code>elpd</code>) and the effective number of parameters <code>p</code>, as well as standard errors and pointwise estimates of each, from which other relevant estimates can be computed.</p><p>Subtypes implement the following functions:</p><ul><li><a href="#ArviZ.ArviZStats.elpd_estimates"><code>elpd_estimates</code></a></li><li><a href="#ArviZ.ArviZStats.information_criterion"><code>information_criterion</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/elpdresult.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.PSISLOOResult" href="#ArviZ.ArviZStats.PSISLOOResult"><code>ArviZ.ArviZStats.PSISLOOResult</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Results of Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO).</p><p>See also: <a href="#ArviZ.ArviZStats.loo"><code>loo</code></a>, <a href="#ArviZ.ArviZStats.AbstractELPDResult"><code>AbstractELPDResult</code></a></p><ul><li><p><code>estimates</code>: Estimates of the expected log pointwise predictive density (ELPD) and effective number of parameters (p)</p></li><li><p><code>pointwise</code>: Pointwise estimates</p></li><li><p><code>psis_result</code>: Pareto-smoothed importance sampling (PSIS) results</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/loo.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.WAICResult" href="#ArviZ.ArviZStats.WAICResult"><code>ArviZ.ArviZStats.WAICResult</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Results of computing the widely applicable information criterion (WAIC).</p><p>See also: <a href="#ArviZ.ArviZStats.waic"><code>waic</code></a>, <a href="#ArviZ.ArviZStats.AbstractELPDResult"><code>AbstractELPDResult</code></a></p><ul><li><p><code>estimates</code>: Estimates of the expected log pointwise predictive density (ELPD) and effective number of parameters (p)</p></li><li><p><code>pointwise</code>: Pointwise estimates</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/waic.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.elpd_estimates" href="#ArviZ.ArviZStats.elpd_estimates"><code>ArviZ.ArviZStats.elpd_estimates</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">elpd_estimates(result::AbstractELPDResult; pointwise=false) -&gt; (; elpd, elpd_mcse, lpd)</code></pre><p>Return the (E)LPD estimates from the <code>result</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/elpdresult.jl#L25-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.information_criterion" href="#ArviZ.ArviZStats.information_criterion"><code>ArviZ.ArviZStats.information_criterion</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">information_criterion(elpd, scale::Symbol)</code></pre><p>Compute the information criterion for the given <code>scale</code> from the <code>elpd</code> estimate.</p><p><code>scale</code> must be one of (:deviance, :log, :negative_log).</p><p>See also: <a href="api/@ref"><code>effective_number_of_parameters</code></a>, <a href="#ArviZ.ArviZStats.loo"><code>loo</code></a>, <a href="#ArviZ.ArviZStats.waic"><code>waic</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/elpdresult.jl#L32-L40">source</a></section><section><div><pre><code class="nohighlight hljs">information_criterion(result::AbstractELPDResult, scale::Symbol; pointwise=false)</code></pre><p>Compute information criterion for the given <code>scale</code> from the existing ELPD <code>result</code>.</p><p><code>scale</code> must be one of (:deviance, :log, :negative_log).</p><p>If <code>pointwise=true</code>, then pointwise estimates are returned.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/elpdresult.jl#L46-L54">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.loo" href="#ArviZ.ArviZStats.loo"><code>ArviZ.ArviZStats.loo</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">loo(log_likelihood; reff=nothing, kwargs...) -&gt; PSISLOOResult{&lt;:NamedTuple,&lt;:NamedTuple}</code></pre><p>Compute the Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO). <sup class="footnote-reference"><a id="citeref-Vehtari2017" href="#footnote-Vehtari2017">[Vehtari2017]</a></sup><sup class="footnote-reference"><a id="citeref-LOOFAQ" href="#footnote-LOOFAQ">[LOOFAQ]</a></sup></p><p><code>log_likelihood</code> must be an array of log-likelihood values with shape <code>(chains, draws[, params...])</code>.</p><p><strong>Keywords</strong></p><ul><li><code>reff::Union{Real,AbstractArray{&lt;:Real}}</code>: The relative effective sample size(s) of the <em>likelihood</em> values. If an array, it must have the same data dimensions as the corresponding log-likelihood variable. If not provided, then this is estimated using <a href="../diagnostics/#MCMCDiagnosticTools.ess"><code>ess</code></a>.</li><li><code>kwargs</code>: Remaining keywords are forwarded to <a href="#PSIS.psis"><code>psis</code></a>.</li></ul><p>See also: <a href="#ArviZ.ArviZStats.PSISLOOResult"><code>PSISLOOResult</code></a>, <a href="#ArviZ.ArviZStats.waic"><code>waic</code></a></p><p><strong>Examples</strong></p><p>Manually compute <span>$R_\mathrm{eff}$</span> and calculate PSIS-LOO of a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; log_like = PermutedDimsArray(idata.log_likelihood.obs, (:draw, :chain, :school));

julia&gt; reff = ess(log_like; kind=:basic, split_chains=1, relative=true);

julia&gt; loo(log_like; reff)
PSISLOOResult with estimates
 elpd  elpd_mcse    p  p_mcse
  -31        1.4  0.9    0.34

and PSISResult with 500 draws, 4 chains, and 8 parameters
Pareto shape (k) diagnostic values:
                    Count      Min. ESS
 (-Inf, 0.5]  good  7 (87.5%)  151
  (0.5, 0.7]  okay  1 (12.5%)  446</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/loo.jl#L32-L82">source</a></section><section><div><pre><code class="nohighlight hljs">loo(data::Dataset; [var_name::Symbol,] kwargs...) -&gt; PSISLOOResult{&lt;:NamedTuple,&lt;:Dataset}
loo(data::InferenceData; [var_name::Symbol,] kwargs...) -&gt; PSISLOOResult{&lt;:NamedTuple,&lt;:Dataset}</code></pre><p>Compute PSIS-LOO from log-likelihood values in <code>data</code>.</p><p>If more than one log-likelihood variable is present, then <code>var_name</code> must be provided.</p><p><strong>Examples</strong></p><p>Calculate PSIS-LOO of a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; loo(idata)
PSISLOOResult with estimates
 elpd  elpd_mcse    p  p_mcse
  -31        1.4  0.9    0.34

and PSISResult with 500 draws, 4 chains, and 8 parameters
Pareto shape (k) diagnostic values:
                    Count      Min. ESS
 (-Inf, 0.5]  good  6 (75.0%)  135
  (0.5, 0.7]  okay  2 (25.0%)  421</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/loo.jl#L85-L113">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.waic" href="#ArviZ.ArviZStats.waic"><code>ArviZ.ArviZStats.waic</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">waic(log_likelihood::AbstractArray) -&gt; WAICResult{&lt;:NamedTuple,&lt;:NamedTuple}</code></pre><p>Compute the widely applicable information criterion (WAIC).<sup class="footnote-reference"><a id="citeref-Watanabe2010" href="#footnote-Watanabe2010">[Watanabe2010]</a></sup><sup class="footnote-reference"><a id="citeref-Vehtari2017" href="#footnote-Vehtari2017">[Vehtari2017]</a></sup><sup class="footnote-reference"><a id="citeref-LOOFAQ" href="#footnote-LOOFAQ">[LOOFAQ]</a></sup></p><p><code>log_likelihood</code> must be an array of log-likelihood values with shape <code>(chains, draws[, params...])</code>.</p><p>See also: <a href="#ArviZ.ArviZStats.WAICResult"><code>WAICResult</code></a>, <a href="#ArviZ.ArviZStats.loo"><code>loo</code></a></p><p><strong>Examples</strong></p><p>Calculate WAIC of a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; log_like = PermutedDimsArray(idata.log_likelihood.obs, (:draw, :chain, :school));

julia&gt; waic(log_like)
WAICResult with estimates
 elpd  elpd_mcse    p  p_mcse
  -31        1.4  0.9    0.33</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/waic.jl#L26-L60">source</a></section><section><div><pre><code class="nohighlight hljs">waic(data::Dataset; [var_name::Symbol]) -&gt; WAICResult{&lt;:NamedTuple,&lt;:Dataset}
waic(data::InferenceData; [var_name::Symbol]) -&gt; WAICResult{&lt;:NamedTuple,&lt;:Dataset}</code></pre><p>Compute WAIC from log-likelihood values in <code>data</code>.</p><p>If more than one log-likelihood variable is present, then <code>var_name</code> must be provided.</p><p><strong>Examples</strong></p><p>Calculate WAIC of a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; waic(idata)
WAICResult with estimates
 elpd  elpd_mcse    p  p_mcse
  -31        1.4  0.9    0.33</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/waic.jl#L63-L85">source</a></section></article><h2 id="Model-comparison"><a class="docs-heading-anchor" href="#Model-comparison">Model comparison</a><a id="Model-comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Model-comparison" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.ModelComparisonResult" href="#ArviZ.ArviZStats.ModelComparisonResult"><code>ArviZ.ArviZStats.ModelComparisonResult</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ModelComparisonResult</code></pre><p>Result of model comparison using ELPD.</p><p>This struct implements the Tables and TableTraits interfaces.</p><p>Each field returns a collection of the corresponding entry for each model:</p><ul><li><p><code>name</code>: Names of the models, if provided.</p></li><li><p><code>rank</code>: Ranks of the models (ordered by decreasing ELPD)</p></li><li><p><code>elpd_diff</code>: ELPD of a model subtracted from the largest ELPD of any model</p></li><li><p><code>elpd_diff_mcse</code>: Monte Carlo standard error of the ELPD difference</p></li><li><p><code>weight</code>: Model weights computed with <code>weights_method</code></p></li><li><p><code>elpd_result</code>: <code>AbstactELPDResult</code>s for each model, which can be used to access useful stats like ELPD estimates, pointwise estimates, and Pareto shape values for PSIS-LOO</p></li><li><p><code>weights_method</code>: Method used to compute model weights with <a href="#ArviZ.ArviZStats.model_weights"><code>model_weights</code></a></p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/compare.jl#L119-L128">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.compare" href="#ArviZ.ArviZStats.compare"><code>ArviZ.ArviZStats.compare</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">compare(models; kwargs...)</code></pre><p>Compare models based on their expected log pointwise predictive density (ELPD).</p><p><code>models</code> is a <code>Tuple</code>, <code>NamedTuple</code>, or <code>AbstractVector</code> whose values are either <a href="#ArviZ.ArviZStats.AbstractELPDResult"><code>AbstractELPDResult</code></a> entries or any argument to <code>elpd_method</code>, which must produce an <code>AbstractELPDResult</code>.</p><p>The weights are returned in the same type of collection.</p><p>The argument may be any object with a <code>pairs</code> method where each value is either an <a href="../inference_data/#InferenceObjects.InferenceData"><code>InferenceData</code></a> or an <a href="#ArviZ.ArviZStats.AbstractELPDResult"><code>AbstractELPDResult</code></a>.</p><p>The ELPD is estimated either by Pareto smoothed importance sampling leave-one-out cross-validation (LOO) or using the widely applicable information criterion (WAIC). We recommend loo. Read more theory here - in a paper by some of the leading authorities on model comparison dx.doi.org/10.1111/1467-9868.00353</p><p><strong>Arguments</strong></p><ul><li><code>models</code>: a <code>Tuple</code>, <code>NamedTuple</code>, or <code>AbstractVector</code> whose values are either <a href="#ArviZ.ArviZStats.AbstractELPDResult"><code>AbstractELPDResult</code></a> entries or any argument to <code>elpd_method</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><p><code>weights_method::AbstractModelWeightsMethod=Stacking()</code>: the method to be used to weight the models. See <a href="#ArviZ.ArviZStats.model_weights"><code>model_weights</code></a> for details</p><ul><li><code>elpd_method=loo</code>: a method that computes an <code>AbstractELPDResult</code> from an argument in <code>models</code>.</li></ul></li><li><p><code>sort::Bool=true</code>: Whether to sort models by decreasing ELPD.</p></li></ul><p><strong>Returns</strong></p><ul><li><a href="#ArviZ.ArviZStats.ModelComparisonResult"><code>ModelComparisonResult</code></a>: A container for the model comparison results.</li></ul><p><strong>Examples</strong></p><p>Compare the centered and non centered models of the eight school problem using the defaults: <a href="#ArviZ.ArviZStats.loo"><code>loo</code></a> and <a href="#ArviZ.ArviZStats.Stacking"><code>Stacking</code></a> weights:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; models = (
           centered=load_example_data(&quot;centered_eight&quot;),
           non_centered=load_example_data(&quot;non_centered_eight&quot;),
       );

julia&gt; mc = compare(models)
┌ Warning: 1 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...
ModelComparisonResult with Stacking weights
               rank  elpd  elpd_mcse  elpd_diff  elpd_diff_mcse  weight    p   ⋯
 non_centered     1   -31        1.4       0              0.0       1.0  0.9   ⋯
 centered         2   -31        1.4       0.06           0.067     0.0  0.9   ⋯
                                                                1 column omitted</code></pre><p>Compare the same models from pre-computed PSIS-LOO results and computing <a href="#ArviZ.ArviZStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a> weights:</p><pre><code class="language-julia-repl hljs">julia&gt; elpd_results = mc.elpd_result;

julia&gt; compare(elpd_results; weights_method=BootstrappedPseudoBMA())
ModelComparisonResult with BootstrappedPseudoBMA weights
               rank  elpd  elpd_mcse  elpd_diff  elpd_diff_mcse  weight    p   ⋯
 non_centered     1   -31        1.4       0              0.0      0.52  0.9   ⋯
 centered         2   -31        1.4       0.06           0.067    0.48  0.9   ⋯
                                                                1 column omitted</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/compare.jl#L1-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.model_weights" href="#ArviZ.ArviZStats.model_weights"><code>ArviZ.ArviZStats.model_weights</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">model_weights(elpd_results; method=Stacking())
model_weights(method::AbstractModelWeightsMethod, elpd_results)</code></pre><p>Compute weights for each model in <code>elpd_results</code> using <code>method</code>.</p><p><code>elpd_results</code> is a <code>Tuple</code>, <code>NamedTuple</code>, or <code>AbstractVector</code> with <a href="#ArviZ.ArviZStats.AbstractELPDResult"><code>AbstractELPDResult</code></a> entries. The weights are returned in the same type of collection.</p><p><a href="#ArviZ.ArviZStats.Stacking"><code>Stacking</code></a> is the recommended approach, as it performs well even when the true data generating process is not included among the candidate models. See <sup class="footnote-reference"><a id="citeref-YaoVehtari2018" href="#footnote-YaoVehtari2018">[YaoVehtari2018]</a></sup> for details.</p><p>See also: <a href="#ArviZ.ArviZStats.AbstractModelWeightsMethod"><code>AbstractModelWeightsMethod</code></a>, <a href="#ArviZ.ArviZStats.compare"><code>compare</code></a></p><p><strong>Examples</strong></p><p>Compute <a href="#ArviZ.ArviZStats.Stacking"><code>Stacking</code></a> weights for two models:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; models = (
           centered=load_example_data(&quot;centered_eight&quot;),
           non_centered=load_example_data(&quot;non_centered_eight&quot;),
       );

julia&gt; elpd_results = map(loo, models);
┌ Warning: 1 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...

julia&gt; model_weights(elpd_results; method=Stacking()) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :centered     =&gt; 5.34175e-19
  :non_centered =&gt; 1.0</code></pre><p>Now we compute <a href="#ArviZ.ArviZStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a> weights for the same models:</p><pre><code class="language-julia-repl hljs">julia&gt; model_weights(elpd_results; method=BootstrappedPseudoBMA()) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :centered     =&gt; 0.483723
  :non_centered =&gt; 0.516277</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/model_weights.jl#L12-L64">source</a></section></article><p>The following model weighting methods are available</p><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.AbstractModelWeightsMethod" href="#ArviZ.ArviZStats.AbstractModelWeightsMethod"><code>ArviZ.ArviZStats.AbstractModelWeightsMethod</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">abstract type AbstractModelWeightsMethod</code></pre><p>An abstract type representing methods for computing model weights.</p><p>Subtypes implement <a href="#ArviZ.ArviZStats.model_weights"><code>model_weights</code></a><code>(method, elpd_results)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/model_weights.jl#L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.BootstrappedPseudoBMA" href="#ArviZ.ArviZStats.BootstrappedPseudoBMA"><code>ArviZ.ArviZStats.BootstrappedPseudoBMA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct BootstrappedPseudoBMA{R&lt;:Random.AbstractRNG, T&lt;:Real} &lt;: AbstractModelWeightsMethod</code></pre><p>Model weighting method using pseudo Bayesian Model Averaging using Akaike-type weighting with the Bayesian bootstrap (pseudo-BMA+)<sup class="footnote-reference"><a id="citeref-YaoVehtari2018" href="#footnote-YaoVehtari2018">[YaoVehtari2018]</a></sup>.</p><p>The Bayesian bootstrap stabilizes the model weights.</p><pre><code class="nohighlight hljs">BootstrappedPseudoBMA(; rng=Random.default_rng(), samples=1_000, alpha=1)
BootstrappedPseudoBMA(rng, samples, alpha)</code></pre><p>Construct the method.</p><ul><li><p><code>rng::Random.AbstractRNG</code>: The random number generator to use for the Bayesian bootstrap</p></li><li><p><code>samples::Int64</code>: The number of samples to draw for bootstrapping</p></li><li><p><code>alpha::Real</code>: The shape parameter in the Dirichlet distribution used for the Bayesian bootstrap. The default (1) corresponds to a uniform distribution on the simplex.</p></li></ul><p>See also: <a href="#ArviZ.ArviZStats.Stacking"><code>Stacking</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/model_weights.jl#L114">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.PseudoBMA" href="#ArviZ.ArviZStats.PseudoBMA"><code>ArviZ.ArviZStats.PseudoBMA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct PseudoBMA &lt;: AbstractModelWeightsMethod</code></pre><p>Model weighting method using pseudo Bayesian Model Averaging (pseudo-BMA) and Akaike-type weighting.</p><pre><code class="nohighlight hljs">PseudoBMA(; regularize=false)
PseudoBMA(regularize)</code></pre><p>Construct the method with optional regularization of the weights using the standard error of the ELPD estimate.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This approach is not recommended, as it produces unstable weight estimates. It is recommended to instead use <a href="#ArviZ.ArviZStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a> to stabilize the weights or <a href="#ArviZ.ArviZStats.Stacking"><code>Stacking</code></a>. For details, see <sup class="footnote-reference"><a id="citeref-YaoVehtari2018" href="#footnote-YaoVehtari2018">[YaoVehtari2018]</a></sup>.</p></div></div><p>See also: <a href="#ArviZ.ArviZStats.Stacking"><code>Stacking</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/model_weights.jl#L74">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.Stacking" href="#ArviZ.ArviZStats.Stacking"><code>ArviZ.ArviZStats.Stacking</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct Stacking{O&lt;:Optim.AbstractOptimizer} &lt;: AbstractModelWeightsMethod</code></pre><p>Model weighting using stacking of predictive distributions<sup class="footnote-reference"><a id="citeref-YaoVehtari2018" href="#footnote-YaoVehtari2018">[YaoVehtari2018]</a></sup>.</p><pre><code class="nohighlight hljs">Stacking(; optimizer=Optim.LBFGS(), options=Optim.Options()
Stacking(optimizer[, options])</code></pre><p>Construct the method, optionally customizing the optimization.</p><ul><li><p><code>optimizer::Optim.AbstractOptimizer</code>: The optimizer to use for the optimization of the weights. The optimizer must support projected gradient optimization viae a <code>manifold</code> field.</p></li><li><p><code>options::Optim.Options</code>: The Optim options to use for the optimization of the weights.</p></li></ul><p>See also: <a href="#ArviZ.ArviZStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/model_weights.jl#L178">source</a></section></article><h2 id="Predictive-checks"><a class="docs-heading-anchor" href="#Predictive-checks">Predictive checks</a><a id="Predictive-checks-1"></a><a class="docs-heading-anchor-permalink" href="#Predictive-checks" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.loo_pit" href="#ArviZ.ArviZStats.loo_pit"><code>ArviZ.ArviZStats.loo_pit</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">loo_pit(y, y_pred, log_weights; kwargs...) -&gt; Union{Real,AbstractArray}</code></pre><p>Compute leave-one-out probability integral transform (LOO-PIT) checks.</p><p><strong>Arguments</strong></p><ul><li><code>y</code>: array of observations with shape <code>(params...,)</code></li><li><code>y_pred</code>: array of posterior predictive samples with shape <code>(draws, chains, params...)</code>.</li><li><code>log_weights</code>: array of normalized log LOO importance weights with shape <code>(draws, chains, params...)</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>is_discrete</code>: If not provided, then it is set to <code>true</code> iff elements of <code>y</code> and <code>y_pred</code> are all integer-valued. If <code>true</code>, then data are smoothed using <a href="#ArviZ.ArviZStats.smooth_data"><code>smooth_data</code></a> to make them non-discrete before estimating LOO-PIT values.</li><li><code>kwargs</code>: Remaining keywords are forwarded to <code>smooth_data</code> if data is discrete.</li></ul><p><strong>Returns</strong></p><ul><li><code>pitvals</code>: LOO-PIT values with same size as <code>y</code>. If <code>y</code> is a scalar, then <code>pitvals</code> is a scalar.</li></ul><p>LOO-PIT is a marginal posterior predictive check. If <span>$y_{-i}$</span> is the array <span>$y$</span> of observations with the <span>$i$</span>th observation left out, and <span>$y_i^*$</span> is a posterior prediction of the <span>$i$</span>th observation, then the LOO-PIT value for the <span>$i$</span>th observation is defined as</p><p class="math-container">\[P(y_i^* \le y_i \mid y_{-i}) = \int_{-\infty}^{y_i} p(y_i^* \mid y_{-i}) \mathrm{d} y_i^*\]</p><p>The LOO posterior predictions and the corresponding observations should have similar distributions, so if conditional predictive distributions are well-calibrated, then all LOO-PIT values should be approximately uniformly distributed on <span>$[0, 1]$</span>.<sup class="footnote-reference"><a id="citeref-Gabry2019" href="#footnote-Gabry2019">[Gabry2019]</a></sup></p><p><strong>Examples</strong></p><p>Calculate LOO-PIT values using as test quantity the observed values themselves.</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; log_weights = loo(idata; var_name=:obs).psis_result.log_weights;

julia&gt; loo_pit(
            idata.observed_data.obs,
            permutedims(idata.posterior_predictive.obs, (:draw, :chain, :school)),
            log_weights,
        )
8-element DimArray{Float64,1} with dimensions:
  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul&#39;s, Mt. Hermon] Unordered
 &quot;Choate&quot;            0.943511
 &quot;Deerfield&quot;         0.63797
 &quot;Phillips Andover&quot;  0.316697
 &quot;Phillips Exeter&quot;   0.582252
 &quot;Hotchkiss&quot;         0.295321
 &quot;Lawrenceville&quot;     0.403318
 &quot;St. Paul&#39;s&quot;        0.902508
 &quot;Mt. Hermon&quot;        0.655275</code></pre><p>Calculate LOO-PIT values using as test quantity the square of the difference between each observation and <code>mu</code>.</p><pre><code class="language-julia-repl hljs">julia&gt; using DimensionalData, Statistics

julia&gt; T = idata.observed_data.obs .- only(median(idata.posterior.mu; dims=(:draw, :chain)));

julia&gt; T_pred = permutedims(
           broadcast_dims(-, idata.posterior_predictive.obs, idata.posterior.mu),
           (:draw, :chain, :school),
       );

julia&gt; loo_pit(T .^ 2, T_pred .^ 2, log_weights)
8-element DimArray{Float64,1} with dimensions:
  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul&#39;s, Mt. Hermon] Unordered
 &quot;Choate&quot;            0.873577
 &quot;Deerfield&quot;         0.243686
 &quot;Phillips Andover&quot;  0.357563
 &quot;Phillips Exeter&quot;   0.149908
 &quot;Hotchkiss&quot;         0.435094
 &quot;Lawrenceville&quot;     0.220627
 &quot;St. Paul&#39;s&quot;        0.775086
 &quot;Mt. Hermon&quot;        0.296706</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/loo_pit.jl#L1-L96">source</a></section><section><div><pre><code class="nohighlight hljs">loo_pit(idata::InferenceData, log_weights; kwargs...) -&gt; DimArray</code></pre><p>Compute LOO-PIT values using existing normalized log LOO importance weights.</p><p><strong>Keywords</strong></p><ul><li><code>y_name</code>: Name of observed data variable in <code>idata.observed_data</code>. If not provided, then the only observed data variable is used.</li><li><code>y_pred_name</code>: Name of posterior predictive variable in <code>idata.posterior_predictive</code>. If not provided, then <code>y_name</code> is used.</li><li><code>kwargs</code>: Remaining keywords are forwarded to <a href="#ArviZ.ArviZStats.loo_pit"><code>loo_pit</code></a>.</li></ul><p><strong>Examples</strong></p><p>Calculate LOO-PIT values using already computed log weights.</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; loo_result = loo(idata; var_name=:obs);

julia&gt; loo_pit(idata, loo_result.psis_result.log_weights; y_name=:obs)
8-element DimArray{Float64,1} loo_pit_obs with dimensions:
  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul&#39;s, Mt. Hermon] Unordered
 &quot;Choate&quot;            0.943511
 &quot;Deerfield&quot;         0.63797
 &quot;Phillips Andover&quot;  0.316697
 &quot;Phillips Exeter&quot;   0.582252
 &quot;Hotchkiss&quot;         0.295321
 &quot;Lawrenceville&quot;     0.403318
 &quot;St. Paul&#39;s&quot;        0.902508
 &quot;Mt. Hermon&quot;        0.655275</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/loo_pit.jl#L125-L161">source</a></section><section><div><pre><code class="nohighlight hljs">loo_pit(idata::InferenceData; kwargs...) -&gt; DimArray</code></pre><p>Compute LOO-PIT from groups in <code>idata</code> using PSIS-LOO.</p><p>See also: <a href="#ArviZ.ArviZStats.loo"><code>loo</code></a>, <a href="#PSIS.psis"><code>psis</code></a></p><p><strong>Keywords</strong></p><ul><li><code>y_name</code>: Name of observed data variable in <code>idata.observed_data</code>. If not provided, then the only observed data variable is used.</li><li><code>y_pred_name</code>: Name of posterior predictive variable in <code>idata.posterior_predictive</code>. If not provided, then <code>y_name</code> is used.</li><li><code>log_likelihood_name</code>: Name of log-likelihood variable in <code>idata.log_likelihood</code>. If not provided, then <code>y_name</code> is used if <code>idata</code> has a <code>log_likelihood</code> group, otherwise the only variable is used.</li><li><code>reff::Union{Real,AbstractArray{&lt;:Real}}</code>: The relative effective sample size(s) of the <em>likelihood</em> values. If an array, it must have the same data dimensions as the corresponding log-likelihood variable. If not provided, then this is estimated using <a href="../diagnostics/#MCMCDiagnosticTools.ess"><code>ess</code></a>.</li><li><code>kwargs</code>: Remaining keywords are forwarded to <a href="#ArviZ.ArviZStats.loo_pit"><code>loo_pit</code></a>.</li></ul><p><strong>Examples</strong></p><p>Calculate LOO-PIT values using as test quantity the observed values themselves.</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZ, ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; loo_pit(idata; y_name=:obs)
8-element DimArray{Float64,1} loo_pit_obs with dimensions:
  Dim{:school} Categorical{String} String[Choate, Deerfield, …, St. Paul&#39;s, Mt. Hermon] Unordered
 &quot;Choate&quot;            0.943511
 &quot;Deerfield&quot;         0.63797
 &quot;Phillips Andover&quot;  0.316697
 &quot;Phillips Exeter&quot;   0.582252
 &quot;Hotchkiss&quot;         0.295321
 &quot;Lawrenceville&quot;     0.403318
 &quot;St. Paul&#39;s&quot;        0.902508
 &quot;Mt. Hermon&quot;        0.655275</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/loo_pit.jl#L175-L218">source</a></section></article><h3 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ArviZ.ArviZStats.smooth_data" href="#ArviZ.ArviZStats.smooth_data"><code>ArviZ.ArviZStats.smooth_data</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">smooth_data(y; dims=:, interp_method=CubicSpline, offset_frac=0.01)</code></pre><p>Smooth <code>y</code> along <code>dims</code> using <code>interp_method</code>.</p><p><code>interp_method</code> is a 2-argument callabale that takes the arguments <code>y</code> and <code>x</code> and returns a DataInterpolations.jl interpolation method, defaulting to a cubic spline interpolator.</p><p><code>offset_frac</code> is the fraction of the length of <code>y</code> to use as an offset when interpolating.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/ArviZ.jl/blob/c31176a952bb6cd17554eeff3ad5d70f46675368/src/ArviZStats/utils.jl#L169-L178">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Hyndman1996"><a class="tag is-link" href="#citeref-Hyndman1996">Hyndman1996</a>Rob J. Hyndman (1996) Computing and Graphing Highest Density Regions,             Amer. Stat., 50(2): 120-6.             DOI: <a href="https://doi.org/10.1080/00031305.1996.10474359">10.1080/00031305.1996.10474359</a>             <a href="https://doi.org/10.2307/2684423">jstor</a>.</li><li class="footnote" id="footnote-ChenShao1999"><a class="tag is-link" href="#citeref-ChenShao1999">ChenShao1999</a>Ming-Hui Chen &amp; Qi-Man Shao (1999)              Monte Carlo Estimation of Bayesian Credible and HPD Intervals,              J Comput. Graph. Stat., 8:1, 69-92.              DOI: <a href="https://doi.org/10.1080/00031305.1996.10474359">10.1080/10618600.1999.10474802</a>              <a href="https://doi.org/10.2307/1390921">jstor</a>.</li><li class="footnote" id="footnote-GelmanGoodrich2019"><a class="tag is-link" href="#citeref-GelmanGoodrich2019">GelmanGoodrich2019</a>Andrew Gelman, Ben Goodrich, Jonah Gabry &amp; Aki Vehtari (2019) R-squared for Bayesian Regression Models, The American Statistician, 73:3, 307-9, DOI: <a href="https://doi.org/10.1080/00031305.2018.1549100">10.1080/00031305.2018.1549100</a>.</li><li class="footnote" id="footnote-VehtariSimpson2021"><a class="tag is-link" href="#citeref-VehtariSimpson2021">VehtariSimpson2021</a>Vehtari A, Simpson D, Gelman A, Yao Y, Gabry J. (2021). Pareto smoothed importance sampling. <a href="https://arxiv.org/abs/1507.02646v7">arXiv:1507.02646v7</a> [stat.CO]</li><li class="footnote" id="footnote-VehtariSimpson2021"><a class="tag is-link" href="#citeref-VehtariSimpson2021">VehtariSimpson2021</a>Vehtari A, Simpson D, Gelman A, Yao Y, Gabry J. (2021). Pareto smoothed importance sampling. <a href="https://arxiv.org/abs/1507.02646v7">arXiv:1507.02646v7</a> [stat.CO]</li><li class="footnote" id="footnote-VehtariSimpson2021"><a class="tag is-link" href="#citeref-VehtariSimpson2021">VehtariSimpson2021</a>Vehtari A, Simpson D, Gelman A, Yao Y, Gabry J. (2021). Pareto smoothed importance sampling. <a href="https://arxiv.org/abs/1507.02646v7">arXiv:1507.02646v7</a> [stat.CO]</li><li class="footnote" id="footnote-Vehtari2017"><a class="tag is-link" href="#citeref-Vehtari2017">Vehtari2017</a>Vehtari, A., Gelman, A. &amp; Gabry, J. Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Stat Comput 27, 1413–1432 (2017). doi: <a href="https://doi.org/10.1007/s11222-016-9696-4">10.1007/s11222-016-9696-4</a> arXiv: <a href="https://arxiv.org/abs/1507.04544">1507.04544</a></li><li class="footnote" id="footnote-LOOFAQ"><a class="tag is-link" href="#citeref-LOOFAQ">LOOFAQ</a>Aki Vehtari. Cross-validation FAQ. https://mc-stan.org/loo/articles/online-only/faq.html</li><li class="footnote" id="footnote-Watanabe2010"><a class="tag is-link" href="#citeref-Watanabe2010">Watanabe2010</a>Watanabe, S. Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory. 11(116):3571−3594, 2010. https://jmlr.csail.mit.edu/papers/v11/watanabe10a.html</li><li class="footnote" id="footnote-Vehtari2017"><a class="tag is-link" href="#citeref-Vehtari2017">Vehtari2017</a>Vehtari, A., Gelman, A. &amp; Gabry, J. Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Stat Comput 27, 1413–1432 (2017). doi: <a href="https://doi.org/10.1007/s11222-016-9696-4">10.1007/s11222-016-9696-4</a> arXiv: <a href="https://arxiv.org/abs/1507.04544">1507.04544</a></li><li class="footnote" id="footnote-LOOFAQ"><a class="tag is-link" href="#citeref-LOOFAQ">LOOFAQ</a>Aki Vehtari. Cross-validation FAQ. https://mc-stan.org/loo/articles/online-only/faq.html</li><li class="footnote" id="footnote-YaoVehtari2018"><a class="tag is-link" href="#citeref-YaoVehtari2018">YaoVehtari2018</a><p>Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.</p><ol><li>Bayesian Analysis. 13, 3, 917–1007.</li></ol><p>doi: <a href="https://doi.org/10.1214/17-BA1091">10.1214/17-BA1091</a> arXiv: <a href="https://arxiv.org/abs/1704.02030">1704.02030</a></p></li><li class="footnote" id="footnote-YaoVehtari2018"><a class="tag is-link" href="#citeref-YaoVehtari2018">YaoVehtari2018</a><p>Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.</p><ol><li>Bayesian Analysis. 13, 3, 917–1007.</li></ol><p>doi: <a href="https://doi.org/10.1214/17-BA1091">10.1214/17-BA1091</a> arXiv: <a href="https://arxiv.org/abs/1704.02030">1704.02030</a></p></li><li class="footnote" id="footnote-YaoVehtari2018"><a class="tag is-link" href="#citeref-YaoVehtari2018">YaoVehtari2018</a><p>Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.</p><ol><li>Bayesian Analysis. 13, 3, 917–1007.</li></ol><p>doi: <a href="https://doi.org/10.1214/17-BA1091">10.1214/17-BA1091</a> arXiv: <a href="https://arxiv.org/abs/1704.02030">1704.02030</a></p></li><li class="footnote" id="footnote-YaoVehtari2018"><a class="tag is-link" href="#citeref-YaoVehtari2018">YaoVehtari2018</a><p>Yuling Yao, Aki Vehtari, Daniel Simpson, and Andrew Gelman. Using Stacking to Average Bayesian Predictive Distributions.</p><ol><li>Bayesian Analysis. 13, 3, 917–1007.</li></ol><p>doi: <a href="https://doi.org/10.1214/17-BA1091">10.1214/17-BA1091</a> arXiv: <a href="https://arxiv.org/abs/1704.02030">1704.02030</a></p></li><li class="footnote" id="footnote-Gabry2019"><a class="tag is-link" href="#citeref-Gabry2019">Gabry2019</a>Gabry, J., Simpson, D., Vehtari, A., Betancourt, M. &amp; Gelman, A. Visualization in Bayesian Workflow. J. R. Stat. Soc. Ser. A Stat. Soc. 182, 389–402 (2019). doi: <a href="https://doi.org/10.1111/rssa.12378">10.1111/rssa.12378</a> arXiv: <a href="https://arxiv.org/abs/1709.01449">1709.01449</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« API Overview</a><a class="docs-footer-nextpage" href="../diagnostics/">Diagnostics »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Wednesday 2 August 2023 15:01">Wednesday 2 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
