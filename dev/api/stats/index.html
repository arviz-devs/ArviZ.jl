<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Stats · ArviZ.jl</title><meta name="title" content="Stats · ArviZ.jl"/><meta property="og:title" content="Stats · ArviZ.jl"/><meta property="twitter:title" content="Stats · ArviZ.jl"/><meta name="description" content="Documentation for ArviZ.jl."/><meta property="og:description" content="Documentation for ArviZ.jl."/><meta property="twitter:description" content="Documentation for ArviZ.jl."/><meta property="og:url" content="stable/api/stats/"/><meta property="twitter:url" content="stable/api/stats/"/><link rel="canonical" href="stable/api/stats/"/><script async src="https://www.googletagmanager.com/gtag/js?id=G-W1G68W77YV"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-W1G68W77YV', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="ArviZ.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="ArviZ.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../../quickstart/">Quickstart</a></li><li><a class="tocitem" href="../../working_with_inference_data/">Working with <code>InferenceData</code></a></li><li><a class="tocitem" href="../../creating_custom_plots/">Creating custom plots</a></li></ul></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Stats</a><ul class="internal"><li><a class="tocitem" href="#Summary-statistics"><span>Summary statistics</span></a></li><li><a class="tocitem" href="#Credible-intervals"><span>Credible intervals</span></a></li><li><a class="tocitem" href="#Pareto-smoothed-importance-sampling"><span>Pareto-smoothed importance sampling</span></a></li><li><a class="tocitem" href="#Leave-One-Out-Cross-validation-(LOO-CV)"><span>Leave-One-Out Cross-validation (LOO-CV)</span></a></li><li><a class="tocitem" href="#Model-comparison"><span>Model comparison</span></a></li><li><a class="tocitem" href="#Predictive-checks"><span>Predictive checks</span></a></li><li><a class="tocitem" href="#Utilities"><span>Utilities</span></a></li></ul></li><li><a class="tocitem" href="../diagnostics/">Diagnostics</a></li><li><a class="tocitem" href="../data/">Data</a></li><li><input class="collapse-toggle" id="menuitem-3-5" type="checkbox"/><label class="tocitem" for="menuitem-3-5"><span class="docs-label">InferenceObjects</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../inference_data/">InferenceData</a></li><li><a class="tocitem" href="../dataset/">Dataset</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Stats</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Stats</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/arviz-devs/ArviZ.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/arviz-devs/ArviZ.jl/blob/main/docs/src/api/stats.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="stats-api"><a class="docs-heading-anchor" href="#stats-api">Stats</a><a id="stats-api-1"></a><a class="docs-heading-anchor-permalink" href="#stats-api" title="Permalink"></a></h1><ul><li><a href="#PSIS.PSISResult"><code>PSIS.PSISResult</code></a></li><li><a href="#PosteriorStats.AbstractELPDResult"><code>PosteriorStats.AbstractELPDResult</code></a></li><li><a href="#PosteriorStats.AbstractModelWeightsMethod"><code>PosteriorStats.AbstractModelWeightsMethod</code></a></li><li><a href="#PosteriorStats.BootstrappedPseudoBMA"><code>PosteriorStats.BootstrappedPseudoBMA</code></a></li><li><a href="#PosteriorStats.ModelComparisonResult"><code>PosteriorStats.ModelComparisonResult</code></a></li><li><a href="#PosteriorStats.PSISLOOResult"><code>PosteriorStats.PSISLOOResult</code></a></li><li><a href="#PosteriorStats.PseudoBMA"><code>PosteriorStats.PseudoBMA</code></a></li><li><a href="#PosteriorStats.Stacking"><code>PosteriorStats.Stacking</code></a></li><li><a href="#PosteriorStats.SummaryStats"><code>PosteriorStats.SummaryStats</code></a></li><li><a href="#PSIS.PSISPlots.paretoshapeplot"><code>PSIS.PSISPlots.paretoshapeplot</code></a></li><li><a href="#PSIS.ess_is"><code>PSIS.ess_is</code></a></li><li><a href="#PSIS.psis"><code>PSIS.psis</code></a></li><li><a href="#PSIS.psis!"><code>PSIS.psis!</code></a></li><li><a href="#PosteriorStats.compare"><code>PosteriorStats.compare</code></a></li><li><a href="#PosteriorStats.default_summary_stats"><code>PosteriorStats.default_summary_stats</code></a></li><li><a href="#PosteriorStats.elpd_estimates"><code>PosteriorStats.elpd_estimates</code></a></li><li><a href="#PosteriorStats.eti"><code>PosteriorStats.eti</code></a></li><li><a href="#PosteriorStats.eti!"><code>PosteriorStats.eti!</code></a></li><li><a href="#PosteriorStats.hdi"><code>PosteriorStats.hdi</code></a></li><li><a href="#PosteriorStats.hdi!"><code>PosteriorStats.hdi!</code></a></li><li><a href="#PosteriorStats.information_criterion"><code>PosteriorStats.information_criterion</code></a></li><li><a href="#PosteriorStats.kde_reflected"><code>PosteriorStats.kde_reflected</code></a></li><li><a href="#PosteriorStats.loo"><code>PosteriorStats.loo</code></a></li><li><a href="#PosteriorStats.loo_pit"><code>PosteriorStats.loo_pit</code></a></li><li><a href="#PosteriorStats.model_weights"><code>PosteriorStats.model_weights</code></a></li><li><a href="#PosteriorStats.pointwise_loglikelihoods"><code>PosteriorStats.pointwise_loglikelihoods</code></a></li><li><a href="#PosteriorStats.r2_score"><code>PosteriorStats.r2_score</code></a></li><li><a href="#PosteriorStats.summarize"><code>PosteriorStats.summarize</code></a></li><li><a href="#StatsBase.summarystats"><code>StatsBase.summarystats</code></a></li></ul><h2 id="Summary-statistics"><a class="docs-heading-anchor" href="#Summary-statistics">Summary statistics</a><a id="Summary-statistics-1"></a><a class="docs-heading-anchor-permalink" href="#Summary-statistics" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="PosteriorStats.SummaryStats"><a class="docstring-binding" href="#PosteriorStats.SummaryStats"><code>PosteriorStats.SummaryStats</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">struct SummaryStats</code></pre><p>A container for a column table of values computed by <a href="#PosteriorStats.summarize"><code>summarize</code></a>.</p><p>This object implements the Tables and TableTraits column table interfaces. It has a custom <code>show</code> method.</p><div class="admonition is-info" id="Note-1c424e74bf16a2f6"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-1c424e74bf16a2f6" title="Permalink"></a></header><div class="admonition-body"><p><code>SummaryStats</code> behaves like an <code>OrderedDict</code> of columns, where the columns can be accessed using either <code>Symbol</code>s or a 1-based integer index. However, this interface is not part of the public API and may change in the future. We recommend using it only interactively.</p></div></div><p><strong>Constructor</strong></p><pre><code class="language-julia hljs">SummaryStats(data; name=&quot;SummaryStats&quot;[, labels])</code></pre><p>Construct a <code>SummaryStats</code> from tabular <code>data</code>.</p><p><code>data</code> must implement the Tables interface. If it contains a column <code>label</code>, this will be used for the row labels or will be replaced with the <code>labels</code> if provided.</p><p><strong>Keywords</strong></p><ul><li><code>name::AbstractString</code>: The name of the collection of summary statistics, used as the   table title in display.</li><li><code>labels::AbstractVector</code>: The names of the parameters in <code>data</code>, used as row labels in   display. If not provided, then the column <code>label</code> in <code>data</code> will be   used if it exists. Otherwise, the parameter names will be numeric indices.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/summarystats.jl#L3-L33">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.default_summary_stats"><a class="docstring-binding" href="#PosteriorStats.default_summary_stats"><code>PosteriorStats.default_summary_stats</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">default_summary_stats(kind::Symbol=:all; kwargs...)</code></pre><p>Return a collection of stats functions based on the named preset <code>kind</code>.</p><p>These functions are then passed to <a href="#PosteriorStats.summarize"><code>summarize</code></a>.</p><p><strong>Arguments</strong></p><ul><li><code>kind::Symbol</code>: The named collection of summary statistics to be computed:<ul><li><code>:all</code>: Everything in <code>:stats</code> and <code>:diagnostics</code></li><li><code>:stats</code>: <code>mean</code>, <code>std</code>, <code>&lt;ci&gt;</code></li><li><code>:diagnostics</code>: <code>ess_tail</code>, <code>ess_bulk</code>, <code>rhat</code>, <code>mcse_mean</code>, <code>mcse_std</code></li><li><code>:all_median</code>: Everything in <code>:stats_median</code> and <code>:diagnostics_median</code></li><li><code>:stats_median</code>: <code>median</code>, <code>mad</code>, <code>&lt;ci&gt;</code></li><li><code>:diagnostics_median</code>: <code>ess_median</code>, <code>ess_tail</code>, <code>rhat</code>, <code>mcse_median</code></li></ul></li></ul><p><strong>Keywords</strong></p><ul><li><code>ci_fun=eti</code>: The function to compute the credible interval <code>&lt;ci&gt;</code>, if any. Supported   options are <a href="#PosteriorStats.eti"><code>eti</code></a> and <a href="#PosteriorStats.hdi"><code>hdi</code></a>. CI column name is   <code>&lt;ci_fun&gt;&lt;100*ci_prob&gt;</code>.</li><li><code>ci_prob=0.89</code>: The probability mass to be contained in the credible   interval <code>&lt;ci&gt;</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/summarize.jl#L156-L170">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.summarize"><a class="docstring-binding" href="#PosteriorStats.summarize"><code>PosteriorStats.summarize</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">summarize(data; kind=:all,kwargs...) -&gt; SummaryStats
summarize(data, stats_funs...; kwargs...) -&gt; SummaryStats</code></pre><p>Compute summary statistics on each param in <code>data</code>.</p><p><strong>Arguments</strong></p><ul><li><code>data</code>: a 3D array of real samples with shape <code>(draws, chains, params)</code> or another object   for which a <code>summarize</code> method is defined.</li><li><code>stats_funs</code>: a collection of functions that reduces a matrix with shape <code>(draws, chains)</code>   to a scalar or a collection of scalars. Alternatively, an item in <code>stats_funs</code> may be a   <code>Pair</code> of the form <code>name =&gt; fun</code> specifying the name to be used for the statistic or of   the form <code>(name1, ...) =&gt; fun</code> when the function returns a collection. When the function   returns a collection, the names in this latter format must be provided.</li></ul><p><strong>Keywords</strong></p><ul><li><p><code>var_names</code>: a collection specifying the names of the parameters in <code>data</code>. If not   provided, the names the indices of the parameter dimension in <code>data</code>.</p></li><li><p><code>name::String</code>: the name of the summary statistics, used as the table title in display.</p></li><li><p><code>kind::Symbol</code>: The named collection of summary statistics to be computed:</p><ul><li><code>:all</code>: Everything in <code>:stats</code> and <code>:diagnostics</code></li><li><code>:stats</code>: <code>mean</code>, <code>std</code>, <code>&lt;ci&gt;</code></li><li><code>:diagnostics</code>: <code>ess_tail</code>, <code>ess_bulk</code>, <code>rhat</code>, <code>mcse_mean</code>, <code>mcse_std</code></li><li><code>:all_median</code>: Everything in <code>:stats_median</code> and <code>:diagnostics_median</code></li><li><code>:stats_median</code>: <code>median</code>, <code>mad</code>, <code>&lt;ci&gt;</code></li><li><code>:diagnostics_median</code>: <code>ess_median</code>, <code>ess_tail</code>, <code>rhat</code>, <code>mcse_median</code></li></ul></li><li><p><code>kwargs</code>: additional keyword arguments passed to <a href="#PosteriorStats.default_summary_stats"><code>default_summary_stats</code></a>,   including:</p><ul><li><code>ci_fun=eti</code>: The function to compute the credible interval <code>&lt;ci&gt;</code>, if any. Supported   options are <a href="#PosteriorStats.eti"><code>eti</code></a> and <a href="#PosteriorStats.hdi"><code>hdi</code></a>. CI column name is   <code>&lt;ci_fun&gt;&lt;100*ci_prob&gt;</code>.</li><li><code>ci_prob=0.89</code>: The probability mass to be contained in the credible   interval <code>&lt;ci&gt;</code>.</li></ul></li></ul><p>See also <a href="#PosteriorStats.SummaryStats"><code>SummaryStats</code></a>, <a href="#PosteriorStats.default_summary_stats"><code>default_summary_stats</code></a></p><p><strong>Extended Help</strong></p><p><strong>Examples</strong></p><p>Compute all summary statistics (the default):</p><details class="admonition is-details" id="Display-precision-a4a8365e4e041127"><summary class="admonition-header">Display precision<a class="admonition-anchor" href="#Display-precision-a4a8365e4e041127" title="Permalink"></a></summary><div class="admonition-body"><p>When an estimator and its MCSE are both computed, the MCSE is used to determine the number of significant digits that will be displayed.</p></div></details><pre><code class="language-julia-repl hljs">julia&gt; using Statistics, StatsBase

julia&gt; x = randn(1000, 4, 3) .+ reshape(0:10:20, 1, 1, :);

julia&gt; summarize(x)
SummaryStats
       mean   std  eti89          ess_tail  ess_bulk  rhat  mcse_mean  mcse_std
 1   0.0003  0.99  -1.57 .. 1.59      3567      3663  1.00      0.016     0.012
 2  10.02    0.99   8.47 .. 11.6      3841      3906  1.00      0.016     0.011
 3  19.98    0.99   18.4 .. 21.6      3892      3749  1.00      0.016     0.012</code></pre><p>Compute just the default statistics with a 94% <a href="#PosteriorStats.hdi">HDI</a>, and provide the parameter names:</p><pre><code class="language-julia-repl hljs">julia&gt; var_names=[:x, :y, :z];

julia&gt; summarize(x; var_names, kind=:stats, ci_fun=hdi, ci_prob=0.94)
SummaryStats
         mean    std  hdi94
 x   0.000275  0.989  -1.92 .. 1.78
 y  10.0       0.988   8.17 .. 11.9
 z  20.0       0.988   18.1 .. 21.9</code></pre><p>Compute <a href="https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.mean"><code>Statistics.mean</code></a>, <a href="https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.std"><code>Statistics.std</code></a> and the Monte Carlo standard error (MCSE) of the mean estimate:</p><pre><code class="language-julia-repl hljs">julia&gt; summarize(x, mean, std, :mcse_mean =&gt; sem; name=&quot;Mean/Std&quot;)
Mean/Std
       mean    std  mcse_mean
 1   0.0003  0.989      0.016
 2  10.02    0.988      0.016
 3  19.98    0.988      0.016</code></pre><p>Compute multiple <a href="https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.quantile">quantiles</a> simultaneously:</p><pre><code class="language-julia-repl hljs">julia&gt; percs = (5, 25, 50, 75, 95);

julia&gt; summarize(x, Symbol.(:q, percs) =&gt; Base.Fix2(quantile, percs ./ 100))
SummaryStats
       q5     q25       q50     q75    q95
 1  -1.61  -0.668   0.00447   0.653   1.64
 2   8.41   9.34   10.0      10.7    11.6
 3  18.4   19.3    20.0      20.6    21.6</code></pre><p><strong>Extending <code>summarize</code> to custom types</strong></p><p>To support computing summary statistics from a custom object <code>MyType</code>, overload the method <code>summarize(::MyType, stats_funs...; kwargs...)</code>, which should ultimately call <code>summarize(::AbstractArray{&lt;:Union{Real,Missing},3}, stats_funs...; other_kwargs...)</code>, where <code>other_kwargs</code> are the keyword arguments passed to <code>summarize</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/summarize.jl#L18-L111">source</a></section></details></article><article><details class="docstring" open="true"><summary id="StatsBase.summarystats"><a class="docstring-binding" href="#StatsBase.summarystats"><code>StatsBase.summarystats</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">summarystats(data::InferenceData; group=:posterior, kwargs...) -&gt; SummaryStats
summarystats(data::Dataset; kwargs...) -&gt; SummaryStats</code></pre><p>Compute default summary statistics for the data using <a href="#PosteriorStats.summarize"><code>PosteriorStats.summarize</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/InferenceObjects.jl/blob/v0.4.14/ext/InferenceObjectsPosteriorStatsExt/summarize.jl#L1-L7">source</a></section></details></article><h2 id="Credible-intervals"><a class="docs-heading-anchor" href="#Credible-intervals">Credible intervals</a><a id="Credible-intervals-1"></a><a class="docs-heading-anchor-permalink" href="#Credible-intervals" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="PosteriorStats.eti"><a class="docstring-binding" href="#PosteriorStats.eti"><code>PosteriorStats.eti</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">eti(samples::AbstractVecOrMat{&lt;:Real}; [prob, kwargs...]) -&gt; IntervalSets.ClosedInterval
eti(samples::AbstractArray{&lt;:Real}; [prob, kwargs...]) -&gt; Array{&lt;:IntervalSets.ClosedInterval}</code></pre><p>Estimate the equal-tailed interval (ETI) of <code>samples</code> for the probability <code>prob</code>.</p><p>The ETI of a given probability is the credible interval wih the property that the probability of being below the interval is equal to the probability of being above it. That is, it is defined by the <code>(1-prob)/2</code> and <code>1 - (1-prob)/2</code> <a href="https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.quantile">quantiles</a> of the samples.</p><p>See also: <a href="#PosteriorStats.eti!"><code>eti!</code></a>, <a href="#PosteriorStats.hdi"><code>hdi</code></a>, <a href="#PosteriorStats.hdi!"><code>hdi!</code></a>.</p><p><strong>Arguments</strong></p><ul><li><code>samples</code>: an array of shape <code>(draws[, chains[, params...]])</code>. If multiple parameters are   present</li></ul><p><strong>Keywords</strong></p><ul><li><code>prob</code>: the probability mass to be contained in the ETI. Default is <code>0.89</code>.</li><li><code>kwargs</code>: remaining keywords are passed to <a href="https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.quantile"><code>Statistics.quantile</code></a>.</li></ul><p><strong>Returns</strong></p><ul><li><code>intervals</code>: If <code>samples</code> is a vector or matrix, then a single   <a href="https://juliamath.github.io/IntervalSets.jl/stable/api/#IntervalSets.ClosedInterval"><code>IntervalSets.ClosedInterval</code></a> is returned. Otherwise, an array with the shape   <code>(params...,)</code>, is returned, containing a marginal ETI for each parameter.</li></ul><div class="admonition is-info" id="Note-e9e8f80563a3e24c"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-e9e8f80563a3e24c" title="Permalink"></a></header><div class="admonition-body"><p>Any default value of <code>prob</code> is arbitrary. The default value of <code>prob=0.89</code> instead of a more common default like <code>prob=0.95</code> is chosen to reminder the user of this arbitrariness.</p></div></div><p><strong>Examples</strong></p><p>Here we calculate the 83% ETI for a normal random variable:</p><pre><code class="language-julia-repl hljs">julia&gt; x = randn(2_000);

julia&gt; eti(x; prob=0.83)
-1.3740585250299766 .. 1.2860771129421198</code></pre><p>We can also calculate the ETI for a 3-dimensional array of samples:</p><pre><code class="language-julia-repl hljs">julia&gt; x = randn(1_000, 1, 1) .+ reshape(0:5:10, 1, 1, :);

julia&gt; eti(x)
3-element Vector{IntervalSets.ClosedInterval{Float64}}:
 -1.610045656629508 .. 1.6318466811022705
 3.389954343370492 .. 6.63184668110227
 8.38995434337049 .. 11.631846681102271</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/eti.jl#L1-L54">source</a></section><section><div><pre><code class="language-julia hljs">eti(data::InferenceData; kwargs...) -&gt; Dataset
eti(data::Dataset; kwargs...) -&gt; Dataset</code></pre><p>Calculate the equal-tailed interval (ETI) for each parameter in the data.</p><p>For more details and a description of the <code>kwargs</code>, see <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.eti"><code>PosteriorStats.eti</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/InferenceObjects.jl/blob/v0.4.14/ext/InferenceObjectsPosteriorStatsExt/ci.jl#L6-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.eti!"><a class="docstring-binding" href="#PosteriorStats.eti!"><code>PosteriorStats.eti!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">eti!(samples::AbstractArray{&lt;:Real}; [prob, kwargs...])</code></pre><p>A version of <a href="#PosteriorStats.eti"><code>eti</code></a> that partially sorts <code>samples</code> in-place while computing the ETI.</p><p>See also: <a href="#PosteriorStats.eti"><code>eti</code></a>, <a href="#PosteriorStats.hdi"><code>hdi</code></a>, <a href="#PosteriorStats.hdi!"><code>hdi!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/eti.jl#L61-L67">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.hdi"><a class="docstring-binding" href="#PosteriorStats.hdi"><code>PosteriorStats.hdi</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">hdi(samples::AbstractVecOrMat{&lt;:Real}; [prob, sorted, method]) -&gt; IntervalSets.ClosedInterval
hdi(samples::AbstractArray{&lt;:Real}; [prob, sorted, method]) -&gt; Array{&lt;:IntervalSets.ClosedInterval}</code></pre><p>Estimate the highest density interval (HDI) of <code>samples</code> for the probability <code>prob</code>.</p><p>The HDI is the minimum width Bayesian credible interval (BCI). That is, it is the smallest possible interval containing <code>(100*prob)</code>% of the probability mass.<a href="@citep">Hyndman1996</a> This implementation uses the algorithm of <a href="@citet">ChenShao1999</a>.</p><p>See also: <a href="#PosteriorStats.hdi!"><code>hdi!</code></a>, <a href="#PosteriorStats.eti"><code>eti</code></a>, <a href="#PosteriorStats.eti!"><code>eti!</code></a>.</p><p><strong>Arguments</strong></p><ul><li><code>samples</code>: an array of shape <code>(draws[, chains[, params...]])</code>. If multiple parameters are   present, a marginal HDI is computed for each.</li></ul><p><strong>Keywords</strong></p><ul><li><code>prob</code>: the probability mass to be contained in the HDI. Default is <code>0.89</code>.</li><li><code>sorted=false</code>: if <code>true</code>, the input samples are assumed to be sorted.</li><li><code>method::Symbol</code>: the method used to estimate the HDI. Available options are:<ul><li><code>:unimodal</code>: Assumes a unimodal distribution (default). Bounds are entries in <code>samples</code>.</li><li><code>:multimodal</code>: Fits a density estimator to <code>samples</code> and finds the HDI of the estimated   density. For continuous data, the density estimator is a kernel density estimate (KDE)   computed using <a href="#PosteriorStats.kde_reflected"><code>kde_reflected</code></a>. For discrete data, a histogram with bin width   1 is used.</li><li><code>:multimodal_sample</code>: Like <code>:multimodal</code>, but uses the density estimator to find the   entries in <code>samples</code> with the highest density and computes the HDI from those points.   This can correct for inaccuracies in the density estimator.</li></ul></li><li><code>is_discrete::Union{Bool,Nothing}=nothing</code>: Specify if the data is discrete   (integer-valued). If <code>nothing</code>, it&#39;s automatically determined.</li><li><code>kwargs</code>: For continuous data and multimodal <code>method</code>s, remaining keywords are forwarded   to <a href="#PosteriorStats.kde_reflected"><code>kde_reflected</code></a>.</li></ul><p><strong>Returns</strong></p><ul><li><code>intervals</code>: If <code>samples</code> is a vector or matrix, then a single   <a href="https://juliamath.github.io/IntervalSets.jl/stable/api/#IntervalSets.ClosedInterval"><code>IntervalSets.ClosedInterval</code></a> is returned for <code>:unimodal</code> method, or a vector   of <code>ClosedInterval</code> for multimodal methods. For higher dimensional inputs, an array with   the shape <code>(params...,)</code> is returned, containing marginal HDIs for each parameter.</li></ul><div class="admonition is-info" id="Note-9fd5f212aeaeb1c6"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-9fd5f212aeaeb1c6" title="Permalink"></a></header><div class="admonition-body"><p>Any default value of <code>prob</code> is arbitrary. The default value of <code>prob=0.89</code> instead of a more common default like <code>prob=0.95</code> is chosen to remind the user of this arbitrariness.</p></div></div><p><strong>Examples</strong></p><p>Here we calculate the 83% HDI for a normal random variable:</p><pre><code class="language-julia-repl hljs">julia&gt; x = randn(2_000);

julia&gt; hdi(x; prob=0.83)
-1.3826605224220527 .. 1.259817149822839</code></pre><p>We can also calculate the HDI for a 3-dimensional array of samples:</p><pre><code class="language-julia-repl hljs">julia&gt; x = randn(1_000, 1, 1) .+ reshape(0:5:10, 1, 1, :);

julia&gt; hdi(x)
3-element Vector{IntervalSets.ClosedInterval{Float64}}:
 -1.5427053100097161 .. 1.5359155759683685
 3.4572946899902837 .. 6.535915575968368
 8.457294689990285 .. 11.53591557596837</code></pre><p>For multimodal distributions, you can use the <code>:multimodal</code> method:</p><pre><code class="language-julia-repl hljs">julia&gt; x = vcat(randn(1000), randn(1000) .+ 5);

julia&gt; hdi(x; method=:multimodal)
2-element Vector{IntervalSets.ClosedInterval{Float64}}:
 -1.684083621714902 .. 1.6431153298071857
 3.4032753058196996 .. 6.724956514470275</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">Hyndman1996</a> Hyndman, J. Comput. Graph. Stat., 50:2 (1996)</li><li><a href="@cite">ChenShao1999</a> Chen &amp; Shao, J Comput. Graph. Stat., 8:1 (1999)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/hdi.jl#L78-L160">source</a></section><section><div><pre><code class="language-julia hljs">hdi(data::InferenceData; kwargs...) -&gt; Dataset
hdi(data::Dataset; kwargs...) -&gt; Dataset</code></pre><p>Calculate the highest density interval (HDI) for each parameter in the data.</p><p>For more details and a description of the <code>kwargs</code>, see <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.hdi"><code>PosteriorStats.hdi</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/InferenceObjects.jl/blob/v0.4.14/ext/InferenceObjectsPosteriorStatsExt/ci.jl#L6-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.hdi!"><a class="docstring-binding" href="#PosteriorStats.hdi!"><code>PosteriorStats.hdi!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">hdi!(samples::AbstractArray{&lt;:Real}; [prob, sorted])</code></pre><p>A version of <a href="#PosteriorStats.hdi"><code>hdi</code></a> that partially sorts <code>samples</code> in-place while computing the HDI.</p><p>See also: <a href="#PosteriorStats.hdi"><code>hdi</code></a>, <a href="#PosteriorStats.eti"><code>eti</code></a>, <a href="#PosteriorStats.eti!"><code>eti!</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/hdi.jl#L166-L172">source</a></section></details></article><h2 id="Pareto-smoothed-importance-sampling"><a class="docs-heading-anchor" href="#Pareto-smoothed-importance-sampling">Pareto-smoothed importance sampling</a><a id="Pareto-smoothed-importance-sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Pareto-smoothed-importance-sampling" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="PSIS.PSISResult"><a class="docstring-binding" href="#PSIS.PSISResult"><code>PSIS.PSISResult</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PSISResult</code></pre><p>Result of Pareto-smoothed importance sampling (PSIS) using <a href="#PSIS.psis"><code>psis</code></a>.</p><p><strong>Properties</strong></p><ul><li><code>log_weights</code>: un-normalized Pareto-smoothed log weights</li><li><code>weights</code>: normalized Pareto-smoothed weights (allocates a copy)</li><li><code>pareto_shape</code>: Pareto <span>$k=ξ$</span> shape parameter</li><li><code>nparams</code>: number of parameters in <code>log_weights</code></li><li><code>ndraws</code>: number of draws in <code>log_weights</code></li><li><code>nchains</code>: number of chains in <code>log_weights</code></li><li><code>reff</code>: the ratio of the effective sample size of the unsmoothed importance ratios and the actual sample size.</li><li><code>ess</code>: estimated effective sample size of estimate of mean using smoothed importance samples (see <a href="#PSIS.ess_is"><code>ess_is</code></a>)</li><li><code>tail_length</code>: length of the upper tail of <code>log_weights</code> that was smoothed</li><li><code>tail_dist</code>: the generalized Pareto distribution that was fit to the tail of <code>log_weights</code>. Note that the tail weights are scaled to have a maximum of 1, so <code>tail_dist * exp(maximum(log_ratios))</code> is the corresponding fit directly to the tail of <code>log_ratios</code>.</li><li><code>normalized::Bool</code>:indicates whether <code>log_weights</code> are log-normalized along the sample dimensions.</li></ul><p><strong>Diagnostic</strong></p><p>The <code>pareto_shape</code> parameter <span>$k=ξ$</span> of the generalized Pareto distribution <code>tail_dist</code> can be used to diagnose reliability and convergence of estimates using the importance weights <a href="@citep">VehtariSimpson2021</a>.</p><ul><li>if <span>$k &lt; \frac{1}{3}$</span>, importance sampling is stable, and importance sampling (IS) and PSIS both are reliable.</li><li>if <span>$k ≤ \frac{1}{2}$</span>, then the importance ratio distributon has finite variance, and the central limit theorem holds. As <span>$k$</span> approaches the upper bound, IS becomes less reliable, while PSIS still works well but with a higher RMSE.</li><li>if <span>$\frac{1}{2} &lt; k ≤ 0.7$</span>, then the variance is infinite, and IS can behave quite poorly. However, PSIS works well in this regime.</li><li>if <span>$0.7 &lt; k ≤ 1$</span>, then it quickly becomes impractical to collect enough importance weights to reliably compute estimates, and importance sampling is not recommended.</li><li>if <span>$k &gt; 1$</span>, then neither the variance nor the mean of the raw importance ratios exists. The convergence rate is close to zero, and bias can be large with practical sample sizes.</li></ul><p>See <a href="#PSIS.PSISPlots.paretoshapeplot"><code>PSISPlots.paretoshapeplot</code></a> for a diagnostic plot.</p><p><strong>References</strong></p><ul><li><a href="@cite">VehtariSimpson2021</a> Vehtari et al. JMLR 25:72 (2021).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PSIS.jl/blob/v0.9.8/src/core.jl#L12-L61">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PSIS.ess_is"><a class="docstring-binding" href="#PSIS.ess_is"><code>PSIS.ess_is</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ess_is(weights; reff=1)</code></pre><p>Estimate effective sample size (ESS) for importance sampling over the sample dimensions.</p><p>Given normalized weights <span>$w_{1:n}$</span>, the ESS is estimated using the L2-norm of the weights:</p><p class="math-container">\[\mathrm{ESS}(w_{1:n}) = \frac{r_{\mathrm{eff}}}{\sum_{i=1}^n w_i^2}\]</p><p>where <span>$r_{\mathrm{eff}}$</span> is the relative efficiency of the <code>log_weights</code>.</p><pre><code class="language-julia hljs">ess_is(result::PSISResult; bad_shape_nan=true)</code></pre><p>Estimate ESS for Pareto-smoothed importance sampling.</p><div class="admonition is-info" id="Note-caa8a047000ed6ac"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-caa8a047000ed6ac" title="Permalink"></a></header><div class="admonition-body"><p>ESS estimates for Pareto shape values <span>$k &gt; 0.7$</span>, which are unreliable and misleadingly high, are set to <code>NaN</code>. To avoid this, set <code>bad_shape_nan=false</code>.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PSIS.jl/blob/v0.9.8/src/ess.jl#L1-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PSIS.PSISPlots.paretoshapeplot"><a class="docstring-binding" href="#PSIS.PSISPlots.paretoshapeplot"><code>PSIS.PSISPlots.paretoshapeplot</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">paretoshapeplot(values; showlines=false, ...)
paretoshapeplot!(values; showlines=false, kwargs...)</code></pre><p>Plot shape parameters of fitted Pareto tail distributions for diagnosing convergence.</p><p><code>values</code> may be either a vector of Pareto shape parameters or a <a href="#PSIS.PSISResult"><code>PSIS.PSISResult</code></a>.</p><p>If <code>showlines==true</code>, horizontal lines indicating relevant Pareto shape thresholds are drawn. See <a href="#PSIS.PSISResult"><code>PSIS.PSISResult</code></a> for an explanation of the thresholds.</p><p>All remaining <code>kwargs</code> are forwarded to the plotting function.</p><p>See <a href="#PSIS.psis"><code>psis</code></a>, <a href="#PSIS.PSISResult"><code>PSISResult</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using PSIS, Distributions, Plots
proposal = Normal()
target = TDist(7)
x = rand(proposal, 1_000, 100)
log_ratios = logpdf.(target, x) .- logpdf.(proposal, x)
result = psis(log_ratios)
paretoshapeplot(result)</code></pre><p>We can also plot the Pareto shape parameters directly:</p><pre><code class="language-julia hljs">paretoshapeplot(result.pareto_shape)</code></pre><p>We can also use <code>plot</code> directly:</p><pre><code class="language-julia hljs">plot(result.pareto_shape; showlines=true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PSIS.jl/blob/v0.9.8/src/recipes/plots.jl#L11-L49">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PSIS.psis"><a class="docstring-binding" href="#PSIS.psis"><code>PSIS.psis</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">psis(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult
psis!(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult</code></pre><p>Compute Pareto smoothed importance sampling (PSIS) log weights <a href="@citep">VehtariSimpson2021</a>.</p><p>While <code>psis</code> computes smoothed log weights out-of-place, <code>psis!</code> smooths them in-place.</p><p><strong>Arguments</strong></p><ul><li><code>log_ratios</code>: an array of logarithms of importance ratios, with size <code>(draws, [chains, [parameters...]])</code>, where <code>chains&gt;1</code> would be used when chains are generated using Markov chain Monte Carlo.</li><li><code>reff::Union{Real,AbstractArray}</code>: the ratio(s) of effective sample size of <code>log_ratios</code> and the actual sample size <code>reff = ess/(draws * chains)</code>, used to account for autocorrelation, e.g. due to Markov chain Monte Carlo. If an array, it must have the size <code>(parameters...,)</code> to match <code>log_ratios</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>warn=true</code>: If <code>true</code>, warning messages are delivered</li><li><code>normalize=true</code>: If <code>true</code>, the log-weights will be log-normalized so that <code>exp.(log_weights)</code> sums to 1 along the sample dimensions.</li></ul><p><strong>Returns</strong></p><ul><li><code>result</code>: a <a href="#PSIS.PSISResult"><code>PSISResult</code></a> object containing the results of the Pareto-smoothing.</li></ul><p>A warning is raised if the Pareto shape parameter <span>$k ≥ 0.7$</span>. See <a href="#PSIS.PSISResult"><code>PSISResult</code></a> for details and <a href="#PSIS.PSISPlots.paretoshapeplot"><code>PSISPlots.paretoshapeplot</code></a> for a diagnostic plot.</p><p><strong>Examples</strong></p><p>Here we smooth log importance ratios for importance sampling 30 isotropic Student <span>$t$</span>-distributed parameters using standard normal distributions as proposals.</p><pre><code class="language-julia-repl hljs">julia&gt; using Distributions

julia&gt; proposal, target = Normal(), TDist(7);

julia&gt; x = rand(proposal, 1_000, 1, 30);  # (ndraws, nchains, nparams)

julia&gt; log_ratios = @. logpdf(target, x) - logpdf(proposal, x);

julia&gt; result = psis(log_ratios)
┌ Warning: 9 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...
┌ Warning: 1 parameters had Pareto shape values k &gt; 1. Corresponding importance sampling estimates are likely to be unstable and are unlikely to converge with additional samples.
└ @ PSIS ~/.julia/packages/PSIS/...
PSISResult with 1000 draws, 1 chains, and 30 parameters
Pareto shape (k) diagnostic values:
                        Count       Min. ESS
 (-Inf, 0.5]  good       7 (23.3%)  959
  (0.5, 0.7]  okay      13 (43.3%)  938
    (0.7, 1]  bad        9 (30.0%)  ——
    (1, Inf)  very bad   1 (3.3%)   ——</code></pre><p>If the draws were generated using MCMC, we can compute the relative efficiency using <a href="https://julia.arviz.org/MCMCDiagnosticTools/stable/#MCMCDiagnosticTools.ess"><code>MCMCDiagnosticTools.ess</code></a>.</p><pre><code class="language-julia-repl hljs">julia&gt; using MCMCDiagnosticTools

julia&gt; reff = ess(log_ratios; kind=:basic, split_chains=1, relative=true);

julia&gt; result = psis(log_ratios, reff)
┌ Warning: 9 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...
┌ Warning: 1 parameters had Pareto shape values k &gt; 1. Corresponding importance sampling estimates are likely to be unstable and are unlikely to converge with additional samples.
└ @ PSIS ~/.julia/packages/PSIS/...
PSISResult with 1000 draws, 1 chains, and 30 parameters
Pareto shape (k) diagnostic values:
                        Count       Min. ESS
 (-Inf, 0.5]  good       9 (30.0%)  806
  (0.5, 0.7]  okay      11 (36.7%)  842
    (0.7, 1]  bad        9 (30.0%)  ——
    (1, Inf)  very bad   1 (3.3%)   ——</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">VehtariSimpson2021</a> Vehtari et al. JMLR 25:72 (2021).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PSIS.jl/blob/v0.9.8/src/core.jl#L176-L260">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PSIS.psis!"><a class="docstring-binding" href="#PSIS.psis!"><code>PSIS.psis!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">psis(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult
psis!(log_ratios, reff = 1.0; kwargs...) -&gt; PSISResult</code></pre><p>Compute Pareto smoothed importance sampling (PSIS) log weights <a href="@citep">VehtariSimpson2021</a>.</p><p>While <code>psis</code> computes smoothed log weights out-of-place, <code>psis!</code> smooths them in-place.</p><p><strong>Arguments</strong></p><ul><li><code>log_ratios</code>: an array of logarithms of importance ratios, with size <code>(draws, [chains, [parameters...]])</code>, where <code>chains&gt;1</code> would be used when chains are generated using Markov chain Monte Carlo.</li><li><code>reff::Union{Real,AbstractArray}</code>: the ratio(s) of effective sample size of <code>log_ratios</code> and the actual sample size <code>reff = ess/(draws * chains)</code>, used to account for autocorrelation, e.g. due to Markov chain Monte Carlo. If an array, it must have the size <code>(parameters...,)</code> to match <code>log_ratios</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>warn=true</code>: If <code>true</code>, warning messages are delivered</li><li><code>normalize=true</code>: If <code>true</code>, the log-weights will be log-normalized so that <code>exp.(log_weights)</code> sums to 1 along the sample dimensions.</li></ul><p><strong>Returns</strong></p><ul><li><code>result</code>: a <a href="#PSIS.PSISResult"><code>PSISResult</code></a> object containing the results of the Pareto-smoothing.</li></ul><p>A warning is raised if the Pareto shape parameter <span>$k ≥ 0.7$</span>. See <a href="#PSIS.PSISResult"><code>PSISResult</code></a> for details and <a href="#PSIS.PSISPlots.paretoshapeplot"><code>PSISPlots.paretoshapeplot</code></a> for a diagnostic plot.</p><p><strong>Examples</strong></p><p>Here we smooth log importance ratios for importance sampling 30 isotropic Student <span>$t$</span>-distributed parameters using standard normal distributions as proposals.</p><pre><code class="language-julia-repl hljs">julia&gt; using Distributions

julia&gt; proposal, target = Normal(), TDist(7);

julia&gt; x = rand(proposal, 1_000, 1, 30);  # (ndraws, nchains, nparams)

julia&gt; log_ratios = @. logpdf(target, x) - logpdf(proposal, x);

julia&gt; result = psis(log_ratios)
┌ Warning: 9 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...
┌ Warning: 1 parameters had Pareto shape values k &gt; 1. Corresponding importance sampling estimates are likely to be unstable and are unlikely to converge with additional samples.
└ @ PSIS ~/.julia/packages/PSIS/...
PSISResult with 1000 draws, 1 chains, and 30 parameters
Pareto shape (k) diagnostic values:
                        Count       Min. ESS
 (-Inf, 0.5]  good       7 (23.3%)  959
  (0.5, 0.7]  okay      13 (43.3%)  938
    (0.7, 1]  bad        9 (30.0%)  ——
    (1, Inf)  very bad   1 (3.3%)   ——</code></pre><p>If the draws were generated using MCMC, we can compute the relative efficiency using <a href="https://julia.arviz.org/MCMCDiagnosticTools/stable/#MCMCDiagnosticTools.ess"><code>MCMCDiagnosticTools.ess</code></a>.</p><pre><code class="language-julia-repl hljs">julia&gt; using MCMCDiagnosticTools

julia&gt; reff = ess(log_ratios; kind=:basic, split_chains=1, relative=true);

julia&gt; result = psis(log_ratios, reff)
┌ Warning: 9 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...
┌ Warning: 1 parameters had Pareto shape values k &gt; 1. Corresponding importance sampling estimates are likely to be unstable and are unlikely to converge with additional samples.
└ @ PSIS ~/.julia/packages/PSIS/...
PSISResult with 1000 draws, 1 chains, and 30 parameters
Pareto shape (k) diagnostic values:
                        Count       Min. ESS
 (-Inf, 0.5]  good       9 (30.0%)  806
  (0.5, 0.7]  okay      11 (36.7%)  842
    (0.7, 1]  bad        9 (30.0%)  ——
    (1, Inf)  very bad   1 (3.3%)   ——</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">VehtariSimpson2021</a> Vehtari et al. JMLR 25:72 (2021).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PSIS.jl/blob/v0.9.8/src/core.jl#L176-L260">source</a></section></details></article><h2 id="Leave-One-Out-Cross-validation-(LOO-CV)"><a class="docs-heading-anchor" href="#Leave-One-Out-Cross-validation-(LOO-CV)">Leave-One-Out Cross-validation (LOO-CV)</a><a id="Leave-One-Out-Cross-validation-(LOO-CV)-1"></a><a class="docs-heading-anchor-permalink" href="#Leave-One-Out-Cross-validation-(LOO-CV)" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="PosteriorStats.AbstractELPDResult"><a class="docstring-binding" href="#PosteriorStats.AbstractELPDResult"><code>PosteriorStats.AbstractELPDResult</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">abstract type AbstractELPDResult</code></pre><p>An abstract type representing the result of an ELPD computation.</p><p>Every subtype stores estimates of both the expected log predictive density (<code>elpd</code>) and the effective number of parameters <code>p</code>, as well as standard errors and pointwise estimates of each, from which other relevant estimates can be computed.</p><p>Subtypes implement the following functions:</p><ul><li><a href="#PosteriorStats.elpd_estimates"><code>elpd_estimates</code></a></li><li><a href="#PosteriorStats.information_criterion"><code>information_criterion</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/elpdresult.jl#L1">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.PSISLOOResult"><a class="docstring-binding" href="#PosteriorStats.PSISLOOResult"><code>PosteriorStats.PSISLOOResult</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Results of Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO).</p><p>See also: <a href="#PosteriorStats.loo"><code>loo</code></a>, <a href="#PosteriorStats.AbstractELPDResult"><code>AbstractELPDResult</code></a></p><ul><li><p><code>estimates</code>: Estimates of the expected log pointwise predictive density (ELPD) and effective number of parameters (p)</p></li><li><p><code>pointwise</code>: Pointwise estimates</p></li><li><p><code>psis_result</code>: A <a href="https://julia.arviz.org/PSIS/stable/api/#PSIS.PSISResult"><code>PSIS.PSISResult</code></a> with Pareto-smoothed importance sampling (PSIS) results</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/loo.jl#L1">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.elpd_estimates"><a class="docstring-binding" href="#PosteriorStats.elpd_estimates"><code>PosteriorStats.elpd_estimates</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">elpd_estimates(result::AbstractELPDResult; pointwise=false) -&gt; (; elpd, se_elpd, lpd)</code></pre><p>Return the (E)LPD estimates from the <code>result</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/elpdresult.jl#L25-L29">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.information_criterion"><a class="docstring-binding" href="#PosteriorStats.information_criterion"><code>PosteriorStats.information_criterion</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">information_criterion(elpd, scale::Symbol)</code></pre><p>Compute the information criterion for the given <code>scale</code> from the <code>elpd</code> estimate.</p><p><code>scale</code> must be one of <code>(:deviance, :log, :negative_log)</code>.</p><p>See also: <a href="#PosteriorStats.loo"><code>loo</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/elpdresult.jl#L32-L40">source</a></section><section><div><pre><code class="language-julia hljs">information_criterion(result::AbstractELPDResult, scale::Symbol; pointwise=false)</code></pre><p>Compute information criterion for the given <code>scale</code> from the existing ELPD <code>result</code>.</p><p><code>scale</code> must be one of <code>(:deviance, :log, :negative_log)</code>.</p><p>If <code>pointwise=true</code>, then pointwise estimates are returned.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/elpdresult.jl#L46-L54">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.loo"><a class="docstring-binding" href="#PosteriorStats.loo"><code>PosteriorStats.loo</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">loo(log_likelihood; reff=nothing, kwargs...) -&gt; PSISLOOResult{&lt;:NamedTuple,&lt;:NamedTuple}</code></pre><p>Compute the Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO). <a href="@cite">Vehtari2017, LOOFAQ</a></p><p><code>log_likelihood</code> must be an array of log-likelihood values with shape <code>(chains, draws[, params...])</code>.</p><p><strong>Keywords</strong></p><ul><li><code>reff::Union{Real,AbstractArray{&lt;:Real}}</code>: The relative effective sample size(s) of the <em>likelihood</em> values. If an array, it must have the same data dimensions as the corresponding log-likelihood variable. If not provided, then this is estimated using <a href="https://julia.arviz.org/MCMCDiagnosticTools/stable/#MCMCDiagnosticTools.ess"><code>MCMCDiagnosticTools.ess</code></a>.</li><li><code>kwargs</code>: Remaining keywords are forwarded to <a href="https://julia.arviz.org/PSIS/stable/api/#PSIS.psis"><code>PSIS.psis</code></a>.</li></ul><p>See also: <a href="#PosteriorStats.PSISLOOResult"><code>PSISLOOResult</code></a></p><p><strong>Examples</strong></p><p>Manually compute <span>$R_\mathrm{eff}$</span> and calculate PSIS-LOO of a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData, LogExpFunctions, MCMCDiagnosticTools

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; log_like = PermutedDimsArray(idata.log_likelihood.obs, (:draw, :chain, :school));

julia&gt; reff = ess(softmax(log_like; dims=(1, 2)); kind=:basic, split_chains=1, relative=true);

julia&gt; loo(log_like; reff)
PSISLOOResult with estimates
 elpd  se_elpd    p  se_p
  -31      1.4  0.9  0.33

and PSISResult with 500 draws, 4 chains, and 8 parameters
Pareto shape (k) diagnostic values:
                    Count      Min. ESS
 (-Inf, 0.5]  good  4 (50.0%)  270
  (0.5, 0.7]  okay  4 (50.0%)  307</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">Vehtari2017</a> Vehtari et al. Stat. Comput. 27 (2017).</li><li><a href="@cite">LOOFAQ</a> Vehtari. Cross-validation FAQ.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/loo.jl#L32-L80">source</a></section><section><div><pre><code class="language-julia hljs">loo(data::Dataset; [var_name::Symbol,] kwargs...) -&gt; PSISLOOResult{&lt;:NamedTuple,&lt;:Dataset}
loo(data::InferenceData; [var_name::Symbol,] kwargs...) -&gt; PSISLOOResult{&lt;:NamedTuple,&lt;:Dataset}</code></pre><p>Compute PSIS-LOO from log-likelihood values in <code>data</code>.</p><p>If more than one log-likelihood variable is present, then <code>var_name</code> must be provided.</p><p>For more details and a description of the <code>kwargs</code>, see <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.loo"><code>PosteriorStats.loo</code></a>.</p><p><strong>Examples</strong></p><p>Calculate PSIS-LOO of a model:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData, PosteriorStats

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; loo(idata)
PSISLOOResult with estimates
 elpd  se_elpd    p  se_p
  -31      1.4  0.9  0.33

and PSISResult with 500 draws, 4 chains, and 8 parameters
Pareto shape (k) diagnostic values:
                    Count      Min. ESS
 (-Inf, 0.5]  good  4 (50.0%)  270
  (0.5, 0.7]  okay  4 (50.0%)  307</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/InferenceObjects.jl/blob/v0.4.14/ext/InferenceObjectsPosteriorStatsExt/loo.jl#L1-L31">source</a></section></details></article><h2 id="Model-comparison"><a class="docs-heading-anchor" href="#Model-comparison">Model comparison</a><a id="Model-comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Model-comparison" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="PosteriorStats.ModelComparisonResult"><a class="docstring-binding" href="#PosteriorStats.ModelComparisonResult"><code>PosteriorStats.ModelComparisonResult</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">ModelComparisonResult</code></pre><p>Result of model comparison using ELPD.</p><p>This struct implements the Tables and TableTraits interfaces.</p><p>Each field returns a collection of the corresponding entry for each model:</p><ul><li><p><code>name</code>: Names of the models, if provided.</p></li><li><p><code>rank</code>: Ranks of the models (ordered by decreasing ELPD)</p></li><li><p><code>elpd_diff</code>: ELPD of a model subtracted from the largest ELPD of any model</p></li><li><p><code>se_elpd_diff</code>: Standard error of the ELPD difference</p></li><li><p><code>weight</code>: Model weights computed with <code>weights_method</code></p></li><li><p><code>elpd_result</code>: <code>AbstactELPDResult</code>s for each model, which can be used to access useful stats like ELPD estimates, pointwise estimates, and Pareto shape values for PSIS-LOO</p></li><li><p><code>weights_method</code>: Method used to compute model weights with <a href="#PosteriorStats.model_weights"><code>model_weights</code></a></p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/compare.jl#L101-L110">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.compare"><a class="docstring-binding" href="#PosteriorStats.compare"><code>PosteriorStats.compare</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">compare(models; kwargs...) -&gt; ModelComparisonResult</code></pre><p>Compare models based on their expected log pointwise predictive density (ELPD).</p><p>The ELPD is estimated by Pareto smoothed importance sampling leave-one-out cross-validation (PSIS-LOO), the same method used by <a href="#PosteriorStats.loo"><code>loo</code></a>. For more theory, see <a href="@citet">Spiegelhalter2002</a>.</p><p><strong>Arguments</strong></p><ul><li><code>models</code>: a <code>Tuple</code>, <code>NamedTuple</code>, or <code>AbstractVector</code> whose values are either <a href="#PosteriorStats.AbstractELPDResult"><code>AbstractELPDResult</code></a> entries or any argument to <a href="#PosteriorStats.loo"><code>loo</code></a>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>weights_method::AbstractModelWeightsMethod=Stacking()</code>: the method to be used to weight the models. See <a href="#PosteriorStats.model_weights"><code>model_weights</code></a> for details</li><li><code>sort::Bool=true</code>: Whether to sort models by decreasing ELPD.</li></ul><p><strong>Returns</strong></p><ul><li><a href="#PosteriorStats.ModelComparisonResult"><code>ModelComparisonResult</code></a>: A container for the model comparison results. The fields contain a similar collection to <code>models</code>.</li></ul><p><strong>Examples</strong></p><p>Compare the centered and non centered models of the eight school problem:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData

julia&gt; models = (
           centered=load_example_data(&quot;centered_eight&quot;),
           non_centered=load_example_data(&quot;non_centered_eight&quot;),
       );

julia&gt; mc = compare(models)
┌ Warning: 1 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...
ModelComparisonResult with Stacking weights
               rank  elpd  se_elpd  elpd_diff  se_elpd_diff  weight    p  se_p
 non_centered     1   -31      1.5       0            0.0       1.0  0.9  0.32
 centered         2   -31      1.4       0.03         0.061     0.0  0.9  0.33
julia&gt; mc.weight |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :non_centered =&gt; 1.0
  :centered     =&gt; 3.50546e-31</code></pre><p>Compare the same models from pre-computed PSIS-LOO results and computing <a href="#PosteriorStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a> weights:</p><pre><code class="language-julia-repl hljs">julia&gt; elpd_results = mc.elpd_result;

julia&gt; compare(elpd_results; weights_method=BootstrappedPseudoBMA())
ModelComparisonResult with BootstrappedPseudoBMA weights
               rank  elpd  se_elpd  elpd_diff  se_elpd_diff  weight    p  se_p
 non_centered     1   -31      1.5       0            0.0      0.51  0.9  0.32
 centered         2   -31      1.4       0.03         0.061    0.49  0.9  0.33</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">Spiegelhalter2002</a> Spiegelhalter et al. J. R. Stat. Soc. B 64 (2002)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/compare.jl#L1-L67">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.model_weights"><a class="docstring-binding" href="#PosteriorStats.model_weights"><code>PosteriorStats.model_weights</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">model_weights(elpd_results; method=Stacking())
model_weights(method::AbstractModelWeightsMethod, elpd_results)</code></pre><p>Compute weights for each model in <code>elpd_results</code> using <code>method</code>.</p><p><code>elpd_results</code> is a <code>Tuple</code>, <code>NamedTuple</code>, or <code>AbstractVector</code> with <a href="#PosteriorStats.AbstractELPDResult"><code>AbstractELPDResult</code></a> entries. The weights are returned in the same type of collection.</p><p><a href="#PosteriorStats.Stacking"><code>Stacking</code></a> is the recommended approach, as it performs well even when the true data generating process is not included among the candidate models. See <a href="@citet">Yao2018</a> for details.</p><p>See also: <a href="#PosteriorStats.AbstractModelWeightsMethod"><code>AbstractModelWeightsMethod</code></a>, <a href="#PosteriorStats.compare"><code>compare</code></a></p><p><strong>Examples</strong></p><p>Compute <a href="#PosteriorStats.Stacking"><code>Stacking</code></a> weights for two models:</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData

julia&gt; models = (
           centered=load_example_data(&quot;centered_eight&quot;),
           non_centered=load_example_data(&quot;non_centered_eight&quot;),
       );

julia&gt; elpd_results = map(models) do idata
           log_like = PermutedDimsArray(idata.log_likelihood.obs, (2, 3, 1))
           return loo(log_like)
       end;
┌ Warning: 1 parameters had Pareto shape values 0.7 &lt; k ≤ 1. Resulting importance sampling estimates are likely to be unstable.
└ @ PSIS ~/.julia/packages/PSIS/...

julia&gt; model_weights(elpd_results; method=Stacking()) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :centered     =&gt; 3.50546e-31
  :non_centered =&gt; 1.0</code></pre><p>Now we compute <a href="#PosteriorStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a> weights for the same models:</p><pre><code class="language-julia-repl hljs">julia&gt; model_weights(elpd_results; method=BootstrappedPseudoBMA()) |&gt; pairs
pairs(::NamedTuple) with 2 entries:
  :centered     =&gt; 0.492513
  :non_centered =&gt; 0.507487</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">Yao2018</a> Yao et al. Bayesian Analysis 13, 3 (2018)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/model_weights.jl#L12-L65">source</a></section></details></article><p>The following model weighting methods are available</p><article><details class="docstring" open="true"><summary id="PosteriorStats.AbstractModelWeightsMethod"><a class="docstring-binding" href="#PosteriorStats.AbstractModelWeightsMethod"><code>PosteriorStats.AbstractModelWeightsMethod</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">abstract type AbstractModelWeightsMethod</code></pre><p>An abstract type representing methods for computing model weights.</p><p>Subtypes implement <a href="#PosteriorStats.model_weights"><code>model_weights</code></a><code>(method, elpd_results)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/model_weights.jl#L3">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.BootstrappedPseudoBMA"><a class="docstring-binding" href="#PosteriorStats.BootstrappedPseudoBMA"><code>PosteriorStats.BootstrappedPseudoBMA</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">struct BootstrappedPseudoBMA{R&lt;:Random.AbstractRNG, T&lt;:Real} &lt;: AbstractModelWeightsMethod</code></pre><p>Model weighting method using pseudo Bayesian Model Averaging using Akaike-type weighting with the Bayesian bootstrap (pseudo-BMA+)<a href="@citep">Yao2018</a>.</p><p>The Bayesian bootstrap stabilizes the model weights.</p><pre><code class="language-julia hljs">BootstrappedPseudoBMA(; rng=Random.default_rng(), samples=1_000, alpha=1)
BootstrappedPseudoBMA(rng, samples, alpha)</code></pre><p>Construct the method.</p><ul><li><p><code>rng::Random.AbstractRNG</code>: The random number generator to use for the Bayesian bootstrap</p></li><li><p><code>samples::Int64</code>: The number of samples to draw for bootstrapping</p></li><li><p><code>alpha::Real</code>: The shape parameter in the Dirichlet distribution used for the Bayesian bootstrap. The default (1) corresponds to a uniform distribution on the simplex.</p></li></ul><p>See also: <a href="#PosteriorStats.Stacking"><code>Stacking</code></a></p><p><strong>References</strong></p><ul><li><a href="@cite">Yao2018</a> Yao et al. Bayesian Analysis 13, 3 (2018)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/model_weights.jl#L113">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.PseudoBMA"><a class="docstring-binding" href="#PosteriorStats.PseudoBMA"><code>PosteriorStats.PseudoBMA</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">struct PseudoBMA &lt;: AbstractModelWeightsMethod</code></pre><p>Model weighting method using pseudo Bayesian Model Averaging (pseudo-BMA) and Akaike-type weighting.</p><pre><code class="language-julia hljs">PseudoBMA(; regularize=false)
PseudoBMA(regularize)</code></pre><p>Construct the method with optional regularization of the weights using the standard error of the ELPD estimate.</p><div class="admonition is-info" id="Note-177d1599c32eaac1"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-177d1599c32eaac1" title="Permalink"></a></header><div class="admonition-body"><p>This approach is not recommended, as it produces unstable weight estimates. It is recommended to instead use <a href="#PosteriorStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a> to stabilize the weights or <a href="#PosteriorStats.Stacking"><code>Stacking</code></a>. For details, see <a href="@citet">Yao2018</a>.</p></div></div><p>See also: <a href="#PosteriorStats.Stacking"><code>Stacking</code></a></p><p><strong>References</strong></p><ul><li><a href="@cite">Yao2018</a> Yao et al. Bayesian Analysis 13, 3 (2018)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/model_weights.jl#L75">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.Stacking"><a class="docstring-binding" href="#PosteriorStats.Stacking"><code>PosteriorStats.Stacking</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">struct Stacking{O&lt;:Optim.AbstractOptimizer} &lt;: AbstractModelWeightsMethod</code></pre><p>Model weighting using stacking of predictive distributions<a href="@citep">Yao2018</a>.</p><pre><code class="language-julia hljs">Stacking(; optimizer=Optim.LBFGS(), options=Optim.Options()
Stacking(optimizer[, options])</code></pre><p>Construct the method, optionally customizing the optimization.</p><ul><li><p><code>optimizer::Optim.AbstractOptimizer</code>: The optimizer to use for the optimization of the weights. The optimizer must support projected gradient optimization via a <code>manifold</code> field.</p></li><li><p><code>options::Optim.Options</code>: The Optim options to use for the optimization of the weights.</p></li></ul><p>See also: <a href="#PosteriorStats.BootstrappedPseudoBMA"><code>BootstrappedPseudoBMA</code></a></p><p><strong>References</strong></p><ul><li><a href="@cite">Yao2018</a> Yao et al. Bayesian Analysis 13, 3 (2018)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/model_weights.jl#L175">source</a></section></details></article><h2 id="Predictive-checks"><a class="docs-heading-anchor" href="#Predictive-checks">Predictive checks</a><a id="Predictive-checks-1"></a><a class="docs-heading-anchor-permalink" href="#Predictive-checks" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="PosteriorStats.loo_pit"><a class="docstring-binding" href="#PosteriorStats.loo_pit"><code>PosteriorStats.loo_pit</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">loo_pit(y, y_pred, log_weights) -&gt; Union{Real,AbstractArray}</code></pre><p>Compute leave-one-out probability integral transform (LOO-PIT) checks.</p><p><strong>Arguments</strong></p><ul><li><code>y</code>: array of observations with shape <code>(params...,)</code></li><li><code>y_pred</code>: array of posterior predictive samples with shape <code>(draws, chains, params...)</code>.</li><li><code>log_weights</code>: array of normalized log LOO importance weights with shape <code>(draws, chains, params...)</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>pitvals</code>: LOO-PIT values with same size as <code>y</code>. If <code>y</code> is a scalar, then <code>pitvals</code> is a scalar.</li></ul><p>LOO-PIT is a marginal posterior predictive check. If <span>$y_{-i}$</span> is the array <span>$y$</span> of observations with the <span>$i$</span>th observation left out, and <span>$y_i^*$</span> is a posterior prediction of the <span>$i$</span>th observation, then the LOO-PIT value for the <span>$i$</span>th observation is defined as</p><p class="math-container">\[P(y_i^* \le y_i \mid y_{-i}) = \int_{-\infty}^{y_i} p(y_i^* \mid y_{-i}) \mathrm{d} y_i^*\]</p><p>The LOO posterior predictions and the corresponding observations should have similar distributions, so if conditional predictive distributions are well-calibrated, then for continuous data, all LOO-PIT values should be approximately uniformly distributed on <span>$[0, 1]$</span>. <a href="@citep">Gabry2019</a></p><div class="admonition is-warning" id="Warning-82cd68cf1207acfe"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-82cd68cf1207acfe" title="Permalink"></a></header><div class="admonition-body"><p>For discrete data, the LOO-PIT values will typically not be uniformly distributed on <span>$[0, 1]$</span>, and this function is not recommended.</p></div></div><p><strong>Examples</strong></p><p>Calculate LOO-PIT values using as test quantity the observed values themselves.</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; y = idata.observed_data.obs;

julia&gt; y_pred = PermutedDimsArray(idata.posterior_predictive.obs, (:draw, :chain, :school));

julia&gt; log_like = PermutedDimsArray(idata.log_likelihood.obs, (:draw, :chain, :school));

julia&gt; log_weights = loo(log_like).psis_result.log_weights;

julia&gt; loo_pit(y, y_pred, log_weights)
┌ 8-element DimArray{Float64, 1} ┐
├────────────────────────────────┴─────────────────────────────── dims ┐
  ↓ school Categorical{String} [&quot;Choate&quot;, …, &quot;Mt. Hermon&quot;] Unordered
└──────────────────────────────────────────────────────────────────────┘
 &quot;Choate&quot;            0.942759
 &quot;Deerfield&quot;         0.641057
 &quot;Phillips Andover&quot;  0.32729
 &quot;Phillips Exeter&quot;   0.581451
 &quot;Hotchkiss&quot;         0.288523
 &quot;Lawrenceville&quot;     0.393741
 &quot;St. Paul&#39;s&quot;        0.886175
 &quot;Mt. Hermon&quot;        0.638821</code></pre><p>Calculate LOO-PIT values using as test quantity the square of the difference between each observation and <code>mu</code>.</p><pre><code class="language-julia-repl hljs">julia&gt; using Statistics

julia&gt; mu = idata.posterior.mu;

julia&gt; T = y .- median(mu);

julia&gt; T_pred = y_pred .- mu;

julia&gt; loo_pit(T .^ 2, T_pred .^ 2, log_weights)
┌ 8-element DimArray{Float64, 1} ┐
├────────────────────────────────┴─────────────────────────────── dims ┐
  ↓ school Categorical{String} [&quot;Choate&quot;, …, &quot;Mt. Hermon&quot;] Unordered
└──────────────────────────────────────────────────────────────────────┘
 &quot;Choate&quot;            0.868148
 &quot;Deerfield&quot;         0.27421
 &quot;Phillips Andover&quot;  0.321719
 &quot;Phillips Exeter&quot;   0.193169
 &quot;Hotchkiss&quot;         0.370422
 &quot;Lawrenceville&quot;     0.195601
 &quot;St. Paul&#39;s&quot;        0.817408
 &quot;Mt. Hermon&quot;        0.326795</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">Gabry2019</a> Gabry et al. J. R. Stat. Soc. Ser. A Stat. Soc. 182 (2019).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/loo_pit.jl#L1-L97">source</a></section><section><div><pre><code class="language-julia hljs">loo_pit(idata::InferenceData, log_weights; kwargs...) -&gt; DimArray</code></pre><p>Compute LOO-PIT values using existing normalized log LOO importance weights.</p><p><strong>Keywords</strong></p><ul><li><code>y_name</code>: Name of observed data variable in <code>idata.observed_data</code>. If not provided, then the only observed data variable is used.</li><li><code>y_pred_name</code>: Name of posterior predictive variable in <code>idata.posterior_predictive</code>. If not provided, then <code>y_name</code> is used.</li><li><code>kwargs</code>: Remaining keywords are forwarded to the base method <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.loo_pit"><code>PosteriorStats.loo_pit</code></a>.</li></ul><p>See <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.loo_pit"><code>PosteriorStats.loo_pit</code></a> for more details.</p><p><strong>Examples</strong></p><p>Calculate LOO-PIT values using already computed log weights.</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData, PosteriorStats

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; loo_result = loo(idata; var_name=:obs);

julia&gt; loo_pit(idata, loo_result.psis_result.log_weights; y_name=:obs)
┌ 8-element DimArray{Float64, 1} loo_pit_obs ┐
├────────────────────────────────────────────┴─────────────────── dims ┐
  ↓ school Categorical{String} [&quot;Choate&quot;, …, &quot;Mt. Hermon&quot;] Unordered
└──────────────────────────────────────────────────────────────────────┘
 &quot;Choate&quot;            0.942759
 &quot;Deerfield&quot;         0.641057
 &quot;Phillips Andover&quot;  0.32729
 &quot;Phillips Exeter&quot;   0.581451
 &quot;Hotchkiss&quot;         0.288523
 &quot;Lawrenceville&quot;     0.393741
 &quot;St. Paul&#39;s&quot;        0.886175
 &quot;Mt. Hermon&quot;        0.638821</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/InferenceObjects.jl/blob/v0.4.14/ext/InferenceObjectsPosteriorStatsExt/loo_pit.jl#L1-L42">source</a></section><section><div><pre><code class="language-julia hljs">loo_pit(idata::InferenceData; kwargs...) -&gt; DimArray</code></pre><p>Compute LOO-PIT from groups in <code>idata</code> using PSIS-LOO.</p><p><strong>Keywords</strong></p><ul><li><code>y_name</code>: Name of observed data variable in <code>idata.observed_data</code>. If not provided, then the only observed data variable is used.</li><li><code>y_pred_name</code>: Name of posterior predictive variable in <code>idata.posterior_predictive</code>. If not provided, then <code>y_name</code> is used.</li><li><code>log_likelihood_name</code>: Name of log-likelihood variable in <code>idata.log_likelihood</code>. If not provided, then <code>y_name</code> is used if <code>idata</code> has a <code>log_likelihood</code> group, otherwise the only variable is used.</li><li><code>reff::Union{Real,AbstractArray{&lt;:Real}}</code>: The relative effective sample size(s) of the <em>likelihood</em> values. If an array, it must have the same data dimensions as the corresponding log-likelihood variable. If not provided, then this is estimated using <code>ess</code>.</li><li><code>kwargs</code>: Remaining keywords are forwarded to <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.loo_pit"><code>PosteriorStats.loo_pit</code></a>.</li></ul><p>See <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.loo_pit"><code>PosteriorStats.loo_pit</code></a> for more details.</p><p><strong>Examples</strong></p><p>Calculate LOO-PIT values using as test quantity the observed values themselves.</p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData, PosteriorStats

julia&gt; idata = load_example_data(&quot;centered_eight&quot;);

julia&gt; loo_pit(idata; y_name=:obs)
┌ 8-element DimArray{Float64, 1} loo_pit_obs ┐
├────────────────────────────────────────────┴─────────────────── dims ┐
  ↓ school Categorical{String} [&quot;Choate&quot;, …, &quot;Mt. Hermon&quot;] Unordered
└──────────────────────────────────────────────────────────────────────┘
 &quot;Choate&quot;            0.942759
 &quot;Deerfield&quot;         0.641057
 &quot;Phillips Andover&quot;  0.32729
 &quot;Phillips Exeter&quot;   0.581451
 &quot;Hotchkiss&quot;         0.288523
 &quot;Lawrenceville&quot;     0.393741
 &quot;St. Paul&#39;s&quot;        0.886175
 &quot;Mt. Hermon&quot;        0.638821</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/InferenceObjects.jl/blob/v0.4.14/ext/InferenceObjectsPosteriorStatsExt/loo_pit.jl#L56-L101">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.r2_score"><a class="docstring-binding" href="#PosteriorStats.r2_score"><code>PosteriorStats.r2_score</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">r2_score(y_true::AbstractVector, y_pred::AbstractArray; kwargs...) -&gt; (; r2, r2_std)</code></pre><p><span>$R²$</span> for linear Bayesian regression models.<a href="@citep">Gelman2019</a></p><p>The <span>$R²$</span>, or coefficient of determination, is defined as the proportion of variance in the data that is explained by the model. For each draw, it is computed as the variance of the predicted values divided by the variance of the predicted values plus the variance of the residuals.</p><p>The distribution of the <span>$R²$</span> scores can then be summarized using a point estimate and a credible interval (CI).</p><p><strong>Arguments</strong></p><ul><li><code>y_true</code>: Observed data of length <code>noutputs</code></li><li><code>y_pred</code>: Predicted data with size <code>(ndraws[, nchains], noutputs)</code></li></ul><p><strong>Keywords</strong></p><ul><li><code>summary::Bool=true</code>: Whether to return a summary or an array of <span>$R²$</span> scores. The summary is a named tuple with the point estimate <code>:r2</code> and the credible interval <code>:&lt;ci_fun&gt;</code>.</li><li><code>point_estimate=Statistics.mean</code>: The function used to compute the point estimate of the <span>$R²$</span> scores if <code>summary</code> is <code>true</code>. Supported options are:<ul><li><a href="https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.mean"><code>Statistics.mean</code></a> (default)</li><li><a href="https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics.median"><code>Statistics.median</code></a></li><li><a href="https://juliastats.org/StatsBase.jl/stable/scalarstats/#StatsBase.mode"><code>StatsBase.mode</code></a></li></ul></li><li><code>ci_fun=eti</code>: The function used to compute the credible interval if <code>summary</code> is <code>true</code>. Supported options are <a href="#PosteriorStats.eti"><code>eti</code></a> and <a href="#PosteriorStats.hdi"><code>hdi</code></a>.</li><li><code>ci_prob=0.89</code>: The probability mass to be contained in the credible interval.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData

julia&gt; idata = load_example_data(&quot;regression1d&quot;);

julia&gt; y_true = idata.observed_data.y;

julia&gt; y_pred = PermutedDimsArray(idata.posterior_predictive.y, (:draw, :chain, :y_dim_0));

julia&gt; r2_score(y_true, y_pred)
(r2 = 0.683196996216511, eti = 0.6230680117869596 .. 0.7384123771046265)</code></pre><p><strong>References</strong></p><ul><li><a href="@cite">Gelman2019</a> Gelman et al, The Am. Stat., 73(3) (2019)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/r2_score.jl#L1-L52">source</a></section><section><div><pre><code class="language-julia hljs">r2_score(idata::InferenceData; y_name, y_pred_name, kwargs...) -&gt; (; r2, &lt;ci&gt;)</code></pre><p>Compute <span>$R²$</span> from <code>idata</code>, automatically formatting the predictions to the correct shape.</p><p><strong>Keywords</strong></p><ul><li><code>y_name</code>: Name of observed data variable in <code>idata.observed_data</code>. If not provided, then the only observed data variable is used.</li><li><code>y_pred_name</code>: Name of posterior predictive variable in <code>idata.posterior_predictive</code>. If not provided, then <code>y_name</code> is used.</li><li><code>kwargs...</code>: Additional keyword arguments to pass to <a href="https://julia.arviz.org/PosteriorStats/stable/api/#PosteriorStats.r2_score"><code>PosteriorStats.r2_score</code></a>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ArviZExampleData, PosteriorStats

julia&gt; idata = load_example_data(&quot;regression10d&quot;);

julia&gt; r2_score(idata)
(r2 = 0.998384805658226, eti = 0.9982167674001565 .. 0.9985401916739318)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/InferenceObjects.jl/blob/v0.4.14/ext/InferenceObjectsPosteriorStatsExt/r2_score.jl#L1-L25">source</a></section></details></article><h2 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="PosteriorStats.kde_reflected"><a class="docstring-binding" href="#PosteriorStats.kde_reflected"><code>PosteriorStats.kde_reflected</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">kde_reflected(data::AbstractVector{&lt;:Real}; bounds=extrema(data), kwargs...)</code></pre><p>Compute the boundary-corrected kernel density estimate (KDE) of <code>data</code> using reflection.</p><p>For <span>$x \in (l, u)$</span>, the reflected KDE has the density</p><p class="math-container">\[\hat{f}_R(x) = \hat{f}(x) + \hat{f}(2l - x) + \hat{f}(2u - x),\]</p><p>where <span>$\hat{f}$</span> is the usual KDE of <code>data</code>. This is equivalent to augmenting the original data with 2 additional copies of the data reflected around each bound, computing the usual KDE, trimming the KDE to the bounds, and renormalizing.</p><p>Any non-finite <code>bounds</code> are ignored. Remaining <code>kwargs</code> are passed to <code>KernelDensity.kde</code>. The default bandwidth is estimated using the Improved Sheather-Jones (ISJ) method <a href="@citep">Botev2010</a>.</p><p><strong>References</strong></p><ul><li><a href="@cite">Botev2010</a> Botev et al. Ann. Stat., 38: 5 (2010)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/kde.jl#L90-L110">source</a></section></details></article><article><details class="docstring" open="true"><summary id="PosteriorStats.pointwise_loglikelihoods"><a class="docstring-binding" href="#PosteriorStats.pointwise_loglikelihoods"><code>PosteriorStats.pointwise_loglikelihoods</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">pointwise_loglikelihoods</code></pre><p>Compute pointwise conditional log-likelihoods for ELPD-based model comparison/validation.</p><p>Given model parameters <span>$\theta$</span> and observations <span>$y$</span>, the pointwise conditional log-likelihood of <span>$y_i$</span> given <span>$y_{-i}$</span> (the elements of <span>$y$</span> excluding <span>$y_i$</span>) and <span>$\theta$</span> is defined as</p><p class="math-container">\[\log p(y_i \mid y_{-i}, \theta)\]</p><p>This method is a utility function that dependant packages can override to provide pointwise conditional log-likelihoods for their own models/distributions.</p><p>See also: <a href="#PosteriorStats.loo"><code>loo</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/arviz-devs/PosteriorStats.jl/blob/v0.4.3/src/pointwise_loglikelihoods.jl#L1-L17">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« API Overview</a><a class="docs-footer-nextpage" href="../diagnostics/">Diagnostics »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Saturday 13 December 2025 01:31">Saturday 13 December 2025</span>. Using Julia version 1.12.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
